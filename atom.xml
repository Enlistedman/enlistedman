<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>LJK&#39; Notes</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2019-07-21T13:42:01.909Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>LJK</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Algo-DP</title>
    <link href="http://yoursite.com/2019/07/21/Algo-DP/"/>
    <id>http://yoursite.com/2019/07/21/Algo-DP/</id>
    <published>2019-07-21T09:17:19.000Z</published>
    <updated>2019-07-21T13:42:01.909Z</updated>
    
    <content type="html"><![CDATA[<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script><div id="hbe-security">  <div class="hbe-input-container">  <input type="password" class="hbe-form-control" id="pass" placeholder="Please enter the password to read the blog." />    <label for="pass">Please enter the password to read the blog.</label>    <div class="bottom-line"></div>  </div></div><div id="decryptionError" style="display: none;">Incorrect Password!</div><div id="noContentError" style="display: none;">No content to display!</div><div id="encrypt-blog" style="display:none">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</div><script src="/lib/crypto-js.js"></script><script src="/lib/blog-encrypt.js"></script><link href="/css/blog-encrypt.css" rel="stylesheet" type="text/css">]]></content>
    
    <summary type="html">
    
      The article has been encrypted, please enter your password to view.&lt;br&gt;
    
    </summary>
    
      <category term="Algorithm" scheme="http://yoursite.com/categories/Algorithm/"/>
    
    
      <category term="Algorithm" scheme="http://yoursite.com/tags/Algorithm/"/>
    
  </entry>
  
  <entry>
    <title>Algo-Sort</title>
    <link href="http://yoursite.com/2019/07/18/Algo-Sort/"/>
    <id>http://yoursite.com/2019/07/18/Algo-Sort/</id>
    <published>2019-07-18T09:17:29.000Z</published>
    <updated>2019-07-21T13:50:54.785Z</updated>
    
    <content type="html"><![CDATA[<h2 id="排序"><a href="#排序" class="headerlink" title="排序"></a>排序</h2><ul><li>八大内部排序：直接插入排序，冒泡排序，简单排序，快速排序，堆排序，归并排序，基数排序</li><li>排序的时间/空间复杂度/稳定性<br><img src="/2019/07/18/Algo-Sort/time.png" alt></li></ul><a id="more"></a><h3 id="直接插入排序"><a href="#直接插入排序" class="headerlink" title="直接插入排序"></a>直接插入排序</h3><h3 id="快速排序"><a href="#快速排序" class="headerlink" title="快速排序"></a>快速排序</h3><ul><li>递归<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">quickSort</span><span class="params">(self,m_list,left,right)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> left &lt; right:</span><br><span class="line">            pivot = self.partition(m_list,left,right)</span><br><span class="line">            self.quickSort(m_list,left,pivot<span class="number">-1</span>)</span><br><span class="line">            self.quickSort(m_list,pivot+<span class="number">1</span>,right)</span><br><span class="line">        <span class="keyword">return</span> m_list</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">partition</span><span class="params">(self,m_list,left,right)</span>:</span></span><br><span class="line">        tmp = m_list[left]</span><br><span class="line">        <span class="keyword">while</span> left &lt; right:</span><br><span class="line">            <span class="keyword">while</span> left &lt; right <span class="keyword">and</span> m_list[right] &gt; tmp:</span><br><span class="line">                right -=<span class="number">1</span></span><br><span class="line">            m_list[left] = m_list[right]</span><br><span class="line">            <span class="keyword">while</span> left &lt;right <span class="keyword">and</span>  m_list[left] &lt; tmp:</span><br><span class="line">                left +=<span class="number">1</span></span><br><span class="line">            m_list[right] = m_list[left]</span><br><span class="line">        m_list[left] = tmp</span><br><span class="line">        <span class="keyword">return</span> left</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">"__main__"</span>:</span><br><span class="line">    list_tmp = list(map(int,input().split(<span class="string">" "</span>)))</span><br><span class="line">    solution = Solution()</span><br><span class="line">    res = solution.quickSort(list_tmp,<span class="number">0</span>,len(list_tmp)<span class="number">-1</span>)</span><br><span class="line">    print(res)</span><br></pre></td></tr></table></figure></li></ul><h3 id="堆排序"><a href="#堆排序" class="headerlink" title="堆排序"></a>堆排序</h3><ul><li>步骤：<br>①构建大顶堆<br>②交换堆顶和堆底元素，向下调整堆<br>③重复②操作，直到List剩余一个元素则完成排序<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">heapSort</span><span class="params">(self,ls)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        要点：为了下标操作的方便，需要为出入的list头插入0</span></span><br><span class="line"><span class="string">        步骤：</span></span><br><span class="line"><span class="string">        1.建立大顶堆，从len/2开始调整</span></span><br><span class="line"><span class="string">        2.交换堆顶和堆底元素，然后向下调整</span></span><br><span class="line"><span class="string">        3.重复2操作，直到剩余一个元素</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        length = len(ls) - <span class="number">1</span></span><br><span class="line">        self.buildMaxHeap(ls,length)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(length - <span class="number">1</span>):</span><br><span class="line">            tmp = ls[length-i]</span><br><span class="line">            ls[length-i] = ls[<span class="number">1</span>]</span><br><span class="line">            ls[<span class="number">1</span>] = tmp</span><br><span class="line">            self.adjustDown(ls,<span class="number">1</span>,length-i<span class="number">-1</span>)</span><br><span class="line">        <span class="keyword">return</span> ls[<span class="number">1</span>:]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">buildMaxHeap</span><span class="params">(self,ls,len)</span>:</span></span><br><span class="line">        length = len//<span class="number">2</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>,length):</span><br><span class="line">            self.adjustDown(ls,length - i,len)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">adjustDown</span><span class="params">(self,ls,low,high)</span>:</span></span><br><span class="line">        tmp = ls[low]</span><br><span class="line">        i = low</span><br><span class="line">        k =  <span class="number">2</span>*i</span><br><span class="line">        <span class="keyword">while</span> k &lt;= high:</span><br><span class="line">            <span class="keyword">if</span> k &lt; high <span class="keyword">and</span> ls[k] &lt;ls[k + <span class="number">1</span>]:</span><br><span class="line">                k +=<span class="number">1</span></span><br><span class="line">            <span class="keyword">if</span> ls[k] &gt; tmp:</span><br><span class="line">                ls[i] = ls[k]</span><br><span class="line">                i = k</span><br><span class="line">                k = <span class="number">2</span>*k</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">        ls[i] = tmp</span><br></pre></td></tr></table></figure></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;排序&quot;&gt;&lt;a href=&quot;#排序&quot; class=&quot;headerlink&quot; title=&quot;排序&quot;&gt;&lt;/a&gt;排序&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;八大内部排序：直接插入排序，冒泡排序，简单排序，快速排序，堆排序，归并排序，基数排序&lt;/li&gt;
&lt;li&gt;排序的时间/空间复杂度/稳定性&lt;br&gt;&lt;img src=&quot;/2019/07/18/Algo-Sort/time.png&quot; alt&gt;&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
      <category term="Algorithm" scheme="http://yoursite.com/categories/Algorithm/"/>
    
    
      <category term="Algorithm" scheme="http://yoursite.com/tags/Algorithm/"/>
    
  </entry>
  
  <entry>
    <title>Algo-List</title>
    <link href="http://yoursite.com/2019/07/16/Algo-List/"/>
    <id>http://yoursite.com/2019/07/16/Algo-List/</id>
    <published>2019-07-16T09:17:03.000Z</published>
    <updated>2019-07-21T13:31:58.458Z</updated>
    
    <content type="html"><![CDATA[<h2 id="链表"><a href="#链表" class="headerlink" title="链表"></a>链表</h2><h3 id="技巧"><a href="#技巧" class="headerlink" title="技巧"></a>技巧</h3><ol><li>借助双指针，三指针</li><li>使用list，dict - hash table，set，stack来辅助</li></ol><h3 id="常见算法"><a href="#常见算法" class="headerlink" title="常见算法"></a>常见算法</h3><ol><li>从尾到头打印链表</li><li>链表中倒数第K个结点</li><li>反转链表</li><li>合并两个排序的链表</li><li>复杂链表的复制</li><li>两个链表的第一个公共结点</li><li>循环链表的入口节点</li><li>删除链表中的重复节点</li></ol><a id="more"></a><h3 id="常见算法-1"><a href="#常见算法-1" class="headerlink" title="常见算法"></a>常见算法</h3><ol><li>从尾到头打印链表</li></ol><ul><li>思路一，将链表反转，然后打印。</li><li>思路二，逆向就想到栈，借助栈打印。<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding:utf-8 -*-</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ListNode</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        self.val = x</span><br><span class="line">        self.next = <span class="literal">None</span></span><br><span class="line"> </span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="comment"># 返回从尾部到头部的列表值序列，例如[1,2,3]</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">printListFromTailToHead</span><span class="params">(self, listNode)</span>:</span></span><br><span class="line">        <span class="comment"># write code here</span></span><br><span class="line">        <span class="keyword">if</span> listNode == <span class="literal">None</span>:</span><br><span class="line">            <span class="keyword">return</span> list()</span><br><span class="line">        stack = list()</span><br><span class="line">        p = listNode</span><br><span class="line">        <span class="keyword">while</span> p:</span><br><span class="line">            stack.append(p.val)</span><br><span class="line">            p = p.next</span><br><span class="line">        res = list()</span><br><span class="line">        <span class="keyword">while</span> len(stack) &gt;<span class="number">0</span>:</span><br><span class="line">            res.append(stack.pop(<span class="number">-1</span>))</span><br><span class="line">        <span class="keyword">return</span> res</span><br></pre></td></tr></table></figure></li></ul><ol start="2"><li>链表中倒数第K个结点</li></ol><ul><li>思路一，双指针，让p指针先走k步，然后p,q再同时走。</li><li>需要特别注意的点：<strong>head == None，k==0，len(list)&lt;k，而且特别注意循环判断的条件(0,1)</strong><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">FindKthToTail</span><span class="params">(self, head, k)</span>:</span></span><br><span class="line">        <span class="comment"># write code here</span></span><br><span class="line">        <span class="keyword">if</span> head == <span class="literal">None</span>:</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line">        stack = list()</span><br><span class="line">        p = head</span><br><span class="line">        length = <span class="number">0</span></span><br><span class="line">        res = <span class="literal">None</span></span><br><span class="line">        <span class="keyword">while</span> p:</span><br><span class="line">            length +=<span class="number">1</span></span><br><span class="line">            stack.append(p)</span><br><span class="line">            p = p.next</span><br><span class="line">        print(length,k)</span><br><span class="line">        <span class="keyword">if</span> length &gt;= k:</span><br><span class="line">            <span class="keyword">while</span> k&gt;<span class="number">0</span>:</span><br><span class="line">                res = stack.pop(<span class="number">-1</span>)</span><br><span class="line">                k -=<span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> res</span><br></pre></td></tr></table></figure></li></ul><ol start="3"><li>反转链表</li></ol><ul><li>思路一，用三个相邻指针分别操作，重要的是头结点的next要为none，结束的时候尾节点要跟之前的连接起来。</li><li>思路二，用栈作为索引，重新连接。<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="comment"># 返回ListNode</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">ReverseList</span><span class="params">(self, pHead)</span>:</span></span><br><span class="line">        <span class="comment"># write code here</span></span><br><span class="line">        <span class="keyword">if</span> pHead == <span class="literal">None</span> <span class="keyword">or</span> pHead.next == <span class="literal">None</span>:</span><br><span class="line">            <span class="keyword">return</span> pHead</span><br><span class="line">        p = pHead</span><br><span class="line">        q = pHead.next</span><br><span class="line">        k = pHead.next.next</span><br><span class="line">        p.next = <span class="literal">None</span></span><br><span class="line">        <span class="keyword">while</span> k:</span><br><span class="line">            q.next = p</span><br><span class="line">            p = q</span><br><span class="line">            q = k</span><br><span class="line">            k = k.next</span><br><span class="line">        q.next = p</span><br><span class="line">        <span class="keyword">return</span> q</span><br></pre></td></tr></table></figure></li></ul><ol start="4"><li>合并两个排序的链表</li></ol><ul><li>其实不要考虑的太复杂。</li><li>思路一，首先判空，然后选头节点小的作为新的头节点，然后循环移位，最后将剩余的拼接就好了<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding:utf-8 -*-</span></span><br><span class="line"><span class="comment"># class ListNode:</span></span><br><span class="line"><span class="comment">#     def __init__(self, x):</span></span><br><span class="line"><span class="comment">#         self.val = x</span></span><br><span class="line"><span class="comment">#         self.next = None</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="comment"># 返回合并后列表</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">Merge</span><span class="params">(self, pHead1, pHead2)</span>:</span></span><br><span class="line">        <span class="comment"># write code here</span></span><br><span class="line">        <span class="keyword">if</span> pHead1 == <span class="literal">None</span>:</span><br><span class="line">            <span class="keyword">return</span> pHead2</span><br><span class="line">        <span class="keyword">if</span> pHead2 == <span class="literal">None</span>:</span><br><span class="line">            <span class="keyword">return</span> pHead1</span><br><span class="line">        <span class="keyword">if</span> pHead1.val &lt; pHead2.val:</span><br><span class="line">            head = pHead1</span><br><span class="line">            pHead1 = pHead1.next</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            head = pHead2</span><br><span class="line">            pHead2 = pHead2.next</span><br><span class="line">        p = head</span><br><span class="line">        <span class="keyword">while</span> pHead1 <span class="keyword">and</span> pHead2:</span><br><span class="line">            <span class="keyword">if</span> pHead1.val &lt; pHead2.val:</span><br><span class="line">                p.next = pHead1</span><br><span class="line">                pHead1 = pHead1.next</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                p.next = pHead2</span><br><span class="line">                pHead2 = pHead2.next</span><br><span class="line">            p = p.next</span><br><span class="line">        <span class="keyword">if</span> pHead1 == <span class="literal">None</span>:</span><br><span class="line">            p.next = pHead2</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            p.next = pHead1</span><br><span class="line">        <span class="keyword">return</span> head</span><br></pre></td></tr></table></figure></li></ul><ol start="5"><li>复杂链表的复制</li></ol><ul><li>思路一，先按照next建立新的链表，然后再对应原始列表逐个查找random节点，时间复杂度为O(n2)</li><li>思路二，先按照next建立新的链表，然后使用哈希表进行查找，O(n)+辅助空间</li><li>思路三，新建各个节点在原节点之后，方便连接random，然后再进行奇偶链表差分。<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># encoding: utf-8</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">@author: KK</span></span><br><span class="line"><span class="string">@file: copylsit.py</span></span><br><span class="line"><span class="string">@time: 2019/7/7 14:49</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">RandomListNode</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        self.label = x</span><br><span class="line">        self.next = <span class="literal">None</span></span><br><span class="line">        self.random = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="comment"># 返回 RandomListNode</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">Clone</span><span class="params">(self, pHead)</span>:</span></span><br><span class="line">        <span class="comment"># write code here</span></span><br><span class="line">        <span class="keyword">if</span> pHead == <span class="literal">None</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">        head = RandomListNode(pHead.label)</span><br><span class="line">        <span class="keyword">if</span> pHead.next == <span class="literal">None</span>:</span><br><span class="line">            <span class="keyword">return</span> head</span><br><span class="line"></span><br><span class="line">        p1 = head</span><br><span class="line">        p2 = pHead.next</span><br><span class="line">        <span class="comment"># 按next复制链表</span></span><br><span class="line">        <span class="keyword">while</span> p2:</span><br><span class="line">            q = RandomListNode(p2.label)</span><br><span class="line">            p1.next = q</span><br><span class="line">            p1 = p1.next</span><br><span class="line">            p2 = p2.next</span><br><span class="line">        <span class="comment"># 暴力搜索random节点位置</span></span><br><span class="line">        p1 = head</span><br><span class="line">        p2 = pHead</span><br><span class="line">        <span class="keyword">while</span> p1:</span><br><span class="line">            p = head</span><br><span class="line">            stride = <span class="number">0</span> <span class="keyword">if</span> p2.random==<span class="literal">None</span> <span class="keyword">else</span> self.find(pHead,p2.random)</span><br><span class="line">            <span class="comment"># 这些细节要考虑</span></span><br><span class="line">            <span class="keyword">if</span> stride &gt; <span class="number">0</span>:</span><br><span class="line">                <span class="keyword">while</span> stride &gt; <span class="number">0</span>:</span><br><span class="line">                    p = p.next</span><br><span class="line">                    stride -= <span class="number">1</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                p = <span class="literal">None</span></span><br><span class="line">            p1.random = p</span><br><span class="line">            p1 = p1.next</span><br><span class="line">            p2 = p2.next</span><br><span class="line">        <span class="keyword">return</span> head</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">find</span><span class="params">(self, head,target)</span>:</span></span><br><span class="line">        count = <span class="number">0</span></span><br><span class="line">        p = head</span><br><span class="line">        <span class="keyword">while</span> p != target:</span><br><span class="line">            count += <span class="number">1</span></span><br><span class="line">            p = p.next</span><br><span class="line">        <span class="keyword">return</span> count</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">CloneEnum</span><span class="params">(self, pHead)</span>:</span></span><br><span class="line">        <span class="comment"># 这种递归方式可行，但是存在问题，python中是引用计数，head.random相当于引用原始链表上的节点,本质上没有达到复制的效果。</span></span><br><span class="line">        <span class="keyword">if</span> pHead == <span class="literal">None</span>:</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line">        newNode = RandomListNode(pHead.label)</span><br><span class="line">        newNode.next = self.CloneEnum(pHead.next)</span><br><span class="line">        newNode.random = pHead.random</span><br><span class="line">        <span class="keyword">return</span> newNode</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">CloneHash</span><span class="params">(self,pHead)</span>:</span></span><br><span class="line">        <span class="comment"># 使用hash表的方式进行快速查询操作</span></span><br><span class="line">        <span class="keyword">if</span> pHead == <span class="literal">None</span>:</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line">        hash_dict = &#123;&#125;</span><br><span class="line">        head = RandomListNode(pHead.label)</span><br><span class="line">        hash_dict[pHead] = head</span><br><span class="line">        p = pHead.next</span><br><span class="line">        q = head</span><br><span class="line">        <span class="keyword">while</span> p:</span><br><span class="line">            node = RandomListNode(p.label)</span><br><span class="line">            hash_dict[p] = node</span><br><span class="line">            q.next = node</span><br><span class="line">            p = p.next</span><br><span class="line">            q = q.next</span><br><span class="line">        p = pHead</span><br><span class="line">        q = head</span><br><span class="line">        <span class="keyword">while</span> p:</span><br><span class="line">            <span class="keyword">if</span> p.random != <span class="literal">None</span>:</span><br><span class="line">                q.random = hash_dict[p.random]</span><br><span class="line">            p = p.next</span><br><span class="line">            q = q.next</span><br><span class="line">        <span class="keyword">return</span> head</span><br></pre></td></tr></table></figure></li></ul><ol start="6"><li>两个链表的第一个公共结点(懂得变通)</li></ol><ul><li>思路一，计算两个链表长度差值，让长链表先走差值步，然后一起走，第一个相同结点便可找到。</li><li>思路二，因为两个链表的尾部肯定相同，所以可以从后往前比较，这时候考虑使用栈结构。使用两个辅助栈，从后往前找，最后一个相同元素节点。<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># encoding: utf-8</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">@author: KK</span></span><br><span class="line"><span class="string">@file: firstCommonNode.py</span></span><br><span class="line"><span class="string">@time: 2019/7/7 19:01</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ListNode</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        self.val = x</span><br><span class="line">        self.next = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">FindFirstCommonNode</span><span class="params">(self, pHead1, pHead2)</span>:</span></span><br><span class="line">        <span class="comment"># write code here</span></span><br><span class="line">        <span class="keyword">if</span> pHead1 == <span class="literal">None</span> <span class="keyword">or</span> pHead2 == <span class="literal">None</span>:</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line">        p1 = pHead1</span><br><span class="line">        p2 = pHead2</span><br><span class="line">        len1 = self.get_len(p1)</span><br><span class="line">        len2 = self.get_len(p2)</span><br><span class="line">        stride = len1 - len2 <span class="keyword">if</span> len1 &gt; len2 <span class="keyword">else</span> len2 - len1</span><br><span class="line">        <span class="keyword">if</span> len1 &gt; len2:</span><br><span class="line">            <span class="keyword">while</span> stride &gt; <span class="number">0</span>:</span><br><span class="line">                p1 = p1.next</span><br><span class="line">                stride -=<span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">while</span> stride &gt; <span class="number">0</span>:</span><br><span class="line">                p2 = p2.next</span><br><span class="line">                stride -=<span class="number">1</span></span><br><span class="line">        <span class="keyword">while</span> p1 != p2:</span><br><span class="line">            p1 = p1.next</span><br><span class="line">            p2 = p2.next</span><br><span class="line">        <span class="keyword">return</span> p1</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_len</span><span class="params">(self,p)</span>:</span></span><br><span class="line">        count = <span class="number">0</span></span><br><span class="line">        head = p</span><br><span class="line">        <span class="keyword">while</span> head:</span><br><span class="line">            head = head.next</span><br><span class="line">            count += <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> count</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">FindFirstCommonNodeWithStack</span><span class="params">(self, pHead1, pHead2)</span>:</span></span><br><span class="line">        <span class="comment"># 使用辅助栈</span></span><br><span class="line">        <span class="keyword">if</span> pHead1 == <span class="literal">None</span> <span class="keyword">or</span> pHead2 == <span class="literal">None</span>:</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line">        stack1 = list()</span><br><span class="line">        stack2 = list()</span><br><span class="line">        p1 = pHead1</span><br><span class="line">        p2 = pHead2</span><br><span class="line">        <span class="keyword">while</span> p1:</span><br><span class="line">            stack1.append(p1)</span><br><span class="line">            p1 = p1.next</span><br><span class="line">        <span class="keyword">while</span> p2:</span><br><span class="line">            stack2.append(p2)</span><br><span class="line">            p2 = p2.next</span><br><span class="line">        res = <span class="literal">None</span></span><br><span class="line">        <span class="keyword">while</span> len(stack1)&gt;<span class="number">0</span> <span class="keyword">and</span> len(stack2)&gt;<span class="number">0</span>:</span><br><span class="line">            tmp1 = stack1.pop(<span class="number">-1</span>)</span><br><span class="line">            tmp2 = stack2.pop(<span class="number">-1</span>)</span><br><span class="line">            <span class="keyword">if</span> tmp1 == tmp2:</span><br><span class="line">                res = tmp1</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">        <span class="keyword">return</span> res</span><br></pre></td></tr></table></figure></li></ul><ol start="7"><li>循环链表的入口节点</li></ol><ul><li>思路一，使用set集合的特性，当碰到在set中存在的元素时即为入口节点</li><li>思路二，双指针，比较经典的解法。但是相对来说麻烦一些，先使用双指针判断是否存在环以及环中节点的个数n，然后让指针1先走n步，再让指针2走，当两指针相遇就可以得到入口节点。</li><li>思路三，可以将其中一个链表的首尾相连，然后按照循环节点求入口节点去做。<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># encoding: utf-8</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">@author: KK</span></span><br><span class="line"><span class="string">@file: EntryNodeOfLoop.py</span></span><br><span class="line"><span class="string">@time: 2019/7/7 20:19</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ListNode</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        self.val = x</span><br><span class="line">        self.next = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">EntryNodeOfLoop</span><span class="params">(self, pHead)</span>:</span></span><br><span class="line">        <span class="comment"># write code here</span></span><br><span class="line">        <span class="keyword">if</span> pHead == <span class="literal">None</span>:</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line">        tmp = set()</span><br><span class="line">        p = pHead</span><br><span class="line">        <span class="keyword">while</span> p:</span><br><span class="line">            <span class="keyword">if</span> p <span class="keyword">not</span> <span class="keyword">in</span> tmp:</span><br><span class="line">                tmp.add(p)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">return</span> p</span><br><span class="line">            p = p.next</span><br><span class="line">        <span class="keyword">return</span></span><br></pre></td></tr></table></figure></li></ul><ol start="8"><li>删除链表中的重复节点</li></ol><ul><li>1.重复节点不保留</li><li>思路一，使用字典去计数，最后将count大于1的全部去掉。</li><li>思路二，使用双指针。先初始化一个新的头节点head，两个前后指针p1,p2，判断指针所在元素是否相同，若不同则连接后，同时后移，若相同，则p2移动到下一个不同元素，然后赋值给p1,p2 = p2.next（<strong>这里要注意判断p2是否为None</strong>）。如此往复，不要忘记最后一个节点的连接。<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># encoding: utf-8</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">@author: KK</span></span><br><span class="line"><span class="string">@file: deleteDuplication.py</span></span><br><span class="line"><span class="string">@time: 2019/7/7 20:32</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ListNode</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        self.val = x</span><br><span class="line">        self.next = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">deleteDuplication</span><span class="params">(self, pHead)</span>:</span></span><br><span class="line">        <span class="comment"># 使用双指针</span></span><br><span class="line">        <span class="keyword">if</span> pHead == <span class="literal">None</span>:</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line">        head = ListNode(<span class="number">0</span>)</span><br><span class="line">        p = head</span><br><span class="line">        p1 = pHead</span><br><span class="line">        p2 = pHead.next</span><br><span class="line">        <span class="keyword">while</span> p1 <span class="keyword">and</span> p2:</span><br><span class="line">            <span class="keyword">if</span> p1.val == p2.val:</span><br><span class="line">                <span class="comment"># 注意元素全相同的情况，判断条件要把握好</span></span><br><span class="line">                <span class="keyword">while</span> p2 <span class="keyword">and</span> p1.val == p2.val:</span><br><span class="line">                    p2 = p2.next</span><br><span class="line">                p1 = p2</span><br><span class="line">                <span class="keyword">if</span> p2:</span><br><span class="line">                    p2 = p2.next</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="comment"># 连接操作,只会在元素值不同的情况下进行</span></span><br><span class="line">                p.next = p1</span><br><span class="line">                p = p.next</span><br><span class="line">                p1 = p1.next</span><br><span class="line">                p2 = p2.next</span><br><span class="line">        <span class="comment"># 最后一个节点的连接操作，</span></span><br><span class="line">        p.next = p1</span><br><span class="line">        <span class="keyword">return</span> head.next</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">deleteDuplicationWithDict</span><span class="params">(self, pHead)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> pHead == <span class="literal">None</span>:</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line">        tmp = dict()</span><br><span class="line">        p = pHead</span><br><span class="line">        <span class="keyword">while</span> p:</span><br><span class="line">            <span class="keyword">if</span> p.val <span class="keyword">not</span> <span class="keyword">in</span> tmp.keys():</span><br><span class="line">                tmp[p.val] = <span class="number">1</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                tmp[p.val] += <span class="number">1</span></span><br><span class="line">            p = p.next</span><br><span class="line">        head = ListNode(<span class="number">-1</span>)</span><br><span class="line">        head.next = pHead</span><br><span class="line">        q = head</span><br><span class="line">        p = pHead</span><br><span class="line">        <span class="keyword">while</span> p:</span><br><span class="line">            <span class="keyword">if</span> tmp[p.val] &gt;<span class="number">1</span>:</span><br><span class="line">                p = p.next</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                q.next = p</span><br><span class="line">                q = q.next</span><br><span class="line">                p = p.next</span><br><span class="line">        <span class="comment"># 同样的，最后一个节点不要忘记</span></span><br><span class="line">        q.next = p</span><br><span class="line">        <span class="keyword">return</span> head.next</span><br></pre></td></tr></table></figure></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;链表&quot;&gt;&lt;a href=&quot;#链表&quot; class=&quot;headerlink&quot; title=&quot;链表&quot;&gt;&lt;/a&gt;链表&lt;/h2&gt;&lt;h3 id=&quot;技巧&quot;&gt;&lt;a href=&quot;#技巧&quot; class=&quot;headerlink&quot; title=&quot;技巧&quot;&gt;&lt;/a&gt;技巧&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;借助双指针，三指针&lt;/li&gt;
&lt;li&gt;使用list，dict - hash table，set，stack来辅助&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&quot;常见算法&quot;&gt;&lt;a href=&quot;#常见算法&quot; class=&quot;headerlink&quot; title=&quot;常见算法&quot;&gt;&lt;/a&gt;常见算法&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;从尾到头打印链表&lt;/li&gt;
&lt;li&gt;链表中倒数第K个结点&lt;/li&gt;
&lt;li&gt;反转链表&lt;/li&gt;
&lt;li&gt;合并两个排序的链表&lt;/li&gt;
&lt;li&gt;复杂链表的复制&lt;/li&gt;
&lt;li&gt;两个链表的第一个公共结点&lt;/li&gt;
&lt;li&gt;循环链表的入口节点&lt;/li&gt;
&lt;li&gt;删除链表中的重复节点&lt;/li&gt;
&lt;/ol&gt;
    
    </summary>
    
      <category term="Algorithm" scheme="http://yoursite.com/categories/Algorithm/"/>
    
    
      <category term="Algorithm" scheme="http://yoursite.com/tags/Algorithm/"/>
    
  </entry>
  
  <entry>
    <title>object-detection-summary</title>
    <link href="http://yoursite.com/2019/07/10/object-detection-summary/"/>
    <id>http://yoursite.com/2019/07/10/object-detection-summary/</id>
    <published>2019-07-10T10:07:38.000Z</published>
    <updated>2019-07-21T10:35:03.058Z</updated>
    
    <content type="html"><![CDATA[<h1 id="目标检测（待完善）"><a href="#目标检测（待完善）" class="headerlink" title="目标检测（待完善）"></a>目标检测（待完善）</h1><h2 id="简述"><a href="#简述" class="headerlink" title="简述"></a>简述</h2><ol><li><strong>one-stage</strong></li></ol><ul><li>主要思想：均匀地在图片的不同位置进行密集抽样，抽样时可以采用不同尺度和长宽比，然后利用CNN提取特征后直接进行分类与回归，整个过程只需要一步</li><li>代表：Yolo，SSD</li><li>特点：速度快，准确率一般没有two-stage高</li></ul><ol start="2"><li><strong>two-stage</strong></li></ol><ul><li>主要思想：一阶段生成proposals，二阶段对这些proposals进行分类和回归</li><li>代表：R-CNN，Fast R-CNN, Faster R-CNN</li></ul><a id="more"></a><h2 id="R-CNN-2013-11-mAP-58-5"><a href="#R-CNN-2013-11-mAP-58-5" class="headerlink" title="R-CNN - 2013.11 - mAP:58.5"></a>R-CNN - 2013.11 - mAP:58.5</h2><h3 id="网络结构"><a href="#网络结构" class="headerlink" title="网络结构"></a>网络结构</h3><p><img src="/2019/07/10/object-detection-summary/RCNN.jpg" alt="RCNN" title="RCNN">   </p><ol><li><strong>步骤</strong>  </li></ol><ul><li>找出候选框；   </li><li>利用CNN提取特征向量；   </li><li>利用SVM进行特征向量分类（N个SVM分类器）。</li></ul><ol><li><strong>selective search</strong>   </li></ol><ul><li>首先通过基于图的图像分割方法初始化原始区域，就是将图像分割成很多很多的小块。</li><li>然后我们使用贪心策略，计算每两个相邻的区域的相似度(纹理/颜色/大小)，然后每次合并最相似的两块，直到最终只剩下一块完整的图片。   </li><li>然后这其中每次产生的图像块包括合并的图像块我们都保存下来，这样就得到图像的分层表示。<h3 id="特点-改进点"><a href="#特点-改进点" class="headerlink" title="特点/改进点"></a>特点/改进点</h3></li></ul><ol><li>使用selective search提取预测框。</li><li>使用CNN进行特征提取。<h3 id="优-缺点"><a href="#优-缺点" class="headerlink" title="优/缺点"></a>优/缺点</h3></li><li><strong>优点</strong></li></ol><ul><li>是CNN在目标检测领域得开篇之作，变检测问题为分类问题。</li></ul><ol start="2"><li><strong>缺点</strong></li></ol><ul><li>需要训练三个模型（proposal，CNN，Regression）</li><li>selective search仍然十分耗时</li><li>存在大量得重复计算</li></ul><h2 id="Fast-RCNN-2015-04-mAP-70-fps-0-5"><a href="#Fast-RCNN-2015-04-mAP-70-fps-0-5" class="headerlink" title="Fast RCNN - 2015.04 - mAP:70,fps:0.5"></a>Fast RCNN - 2015.04 - mAP:70,fps:0.5</h2><h3 id="网络结构-1"><a href="#网络结构-1" class="headerlink" title="网络结构"></a>网络结构</h3><h3 id="特点-改进点-1"><a href="#特点-改进点-1" class="headerlink" title="特点/改进点"></a>特点/改进点</h3><h3 id="优-缺点-1"><a href="#优-缺点-1" class="headerlink" title="优/缺点"></a>优/缺点</h3><h2 id="YOLO-v1-2015-06-mAP-63-4-fps-45"><a href="#YOLO-v1-2015-06-mAP-63-4-fps-45" class="headerlink" title="YOLO v1 - 2015.06 - mAP:63.4,fps:45"></a>YOLO v1 - 2015.06 - mAP:63.4,fps:45</h2><h3 id="网络结构-2"><a href="#网络结构-2" class="headerlink" title="网络结构"></a>网络结构</h3><p><img src="/2019/07/10/object-detection-summary/YOLOV1.PNG" alt="Yolo v1" title="Yolo v1">   </p><ol><li><strong>步骤</strong></li></ol><ul><li>对输入图像进行<strong>网格划分</strong>。</li><li>使用CNN网络生成对应大小的feature map，最后使用两个FC层来进行预测。<h3 id="特点-改进点-2"><a href="#特点-改进点-2" class="headerlink" title="特点/改进点"></a>特点/改进点</h3></li></ul><ol><li>抛弃了滑动窗口和RCNN中selective search的方法，而是将image切分为7x7的网格，利用卷积生成相同大小的feature map来进行预测。<h3 id="优-缺点-2"><a href="#优-缺点-2" class="headerlink" title="优/缺点"></a>优/缺点</h3></li><li>优点</li></ol><ul><li>速度很快，155fps</li><li>不容易对背景误判</li></ul><ol start="2"><li>缺点</li></ol><ul><li>每个cell预测2个bbox，但共享一个类别，对密集物体表现不好。</li><li>定位不精准</li><li>对小物体不友好</li></ul><h2 id="Faster-RCNN-2015-06-mAP-73-2-fps-7"><a href="#Faster-RCNN-2015-06-mAP-73-2-fps-7" class="headerlink" title="Faster RCNN - 2015.06 - mAP:73.2,fps:7"></a>Faster RCNN - 2015.06 - mAP:73.2,fps:7</h2><h3 id="网络结构-3"><a href="#网络结构-3" class="headerlink" title="网络结构"></a>网络结构</h3><p><img src="/2019/07/10/object-detection-summary/FASTERRCNN.PNG" alt="Faster RCNN" title="Faster RCNN"></p><ol><li><strong>步骤</strong></li></ol><ul><li>阶段一，特征提取。</li><li>阶段二，使用<strong>RPN提取ROIs</strong>，并对其中部分样本（256）进行二分类和回归，NMS过滤。</li><li>阶段三，使用<strong>ROI Pooling</strong>，对ROIs中的部分ROI进行Pooling操作统一到相同尺度，在做分类和回归，NMS过滤。   <h3 id="特点-改进点-3"><a href="#特点-改进点-3" class="headerlink" title="特点/改进点"></a>特点/改进点</h3></li></ul><ol><li>使用RPN网络代替selective search，极大减少了生成proposals的时间。</li><li>两阶段（粗分类/回归+细分类/回归），可以获得更高的精度。<h3 id="优-缺点-3"><a href="#优-缺点-3" class="headerlink" title="优/缺点"></a>优/缺点</h3></li><li>优点</li></ol><ul><li>检测精度极大提升</li></ul><ol start="2"><li>缺点</li></ol><ul><li>速度比Yolo慢</li></ul><h2 id="SSD-2015-12-mAP-72-1-fps-58"><a href="#SSD-2015-12-mAP-72-1-fps-58" class="headerlink" title="SSD - 2015.12 - mAP:72.1,fps:58"></a>SSD - 2015.12 - mAP:72.1,fps:58</h2><h3 id="网络结构-4"><a href="#网络结构-4" class="headerlink" title="网络结构"></a>网络结构</h3><p><img src="/2019/07/10/object-detection-summary/SSD.PNG" alt="SSD" title="SSD"></p><ol><li><strong>步骤</strong></li></ol><ul><li>输入图像可以为300x300/512x512</li><li>使用CNN（VGG16改装版）进行特征提取。</li><li>结合5层不同尺度的feature map进行不同尺度（<strong>anchors</strong>）物体的预测。<h3 id="特点-改进点-4"><a href="#特点-改进点-4" class="headerlink" title="特点/改进点"></a>特点/改进点</h3></li></ul><ol><li>改Yolo的FC层预测为<strong>卷积预测</strong>，每个预测框输出一套对应的检测值。</li><li>使用了<strong>FPN</strong>（5层）。</li><li>借鉴了Faster RCNN的<strong>anchor</strong>。<h3 id="优-缺点-4"><a href="#优-缺点-4" class="headerlink" title="优/缺点"></a>优/缺点</h3></li><li>优点</li></ol><ul><li>准确度比Yolo好</li><li>对小物体的检测也比Yolo好</li></ul><h2 id="YOLO-v2-2016"><a href="#YOLO-v2-2016" class="headerlink" title="YOLO v2 - 2016"></a>YOLO v2 - 2016</h2><h3 id="网络结构-5"><a href="#网络结构-5" class="headerlink" title="网络结构"></a>网络结构</h3><h3 id="特点-改进点-5"><a href="#特点-改进点-5" class="headerlink" title="特点/改进点"></a>特点/改进点</h3><ol><li>高分辨率输入</li><li>BN层</li><li>卷积预测 + anchors</li><li>边界框聚类分析</li><li>DarkNet-19</li><li>位置预测限定（沿用Yolo v1思想）</li><li>pass through层（信息融合）</li><li>多尺度输入训练<h3 id="优-缺点-5"><a href="#优-缺点-5" class="headerlink" title="优/缺点"></a>优/缺点</h3></li><li>优点</li></ol><ul><li>引入了其他文章的点，性能提升很多</li></ul><ol start="2"><li>缺点</li></ol><ul><li>对小物体的检测仍然不友好</li></ul><h2 id="YOLO-v3-2017"><a href="#YOLO-v3-2017" class="headerlink" title="YOLO v3 - 2017"></a>YOLO v3 - 2017</h2><h3 id="网络结构-6"><a href="#网络结构-6" class="headerlink" title="网络结构"></a>网络结构</h3><h3 id="特点-改进点-6"><a href="#特点-改进点-6" class="headerlink" title="特点/改进点"></a>特点/改进点</h3><ol><li>使用了FPN结构</li><li>DarkNet-53</li><li>Loss Function: softmax -&gt; logistic loss<h3 id="优-缺点-6"><a href="#优-缺点-6" class="headerlink" title="优/缺点"></a>优/缺点</h3></li><li>优点</li></ol><ul><li>对小物体的检测有很好的改善</li><li>性能提升</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;目标检测（待完善）&quot;&gt;&lt;a href=&quot;#目标检测（待完善）&quot; class=&quot;headerlink&quot; title=&quot;目标检测（待完善）&quot;&gt;&lt;/a&gt;目标检测（待完善）&lt;/h1&gt;&lt;h2 id=&quot;简述&quot;&gt;&lt;a href=&quot;#简述&quot; class=&quot;headerlink&quot; title=&quot;简述&quot;&gt;&lt;/a&gt;简述&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;one-stage&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;主要思想：均匀地在图片的不同位置进行密集抽样，抽样时可以采用不同尺度和长宽比，然后利用CNN提取特征后直接进行分类与回归，整个过程只需要一步&lt;/li&gt;
&lt;li&gt;代表：Yolo，SSD&lt;/li&gt;
&lt;li&gt;特点：速度快，准确率一般没有two-stage高&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start=&quot;2&quot;&gt;
&lt;li&gt;&lt;strong&gt;two-stage&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;主要思想：一阶段生成proposals，二阶段对这些proposals进行分类和回归&lt;/li&gt;
&lt;li&gt;代表：R-CNN，Fast R-CNN, Faster R-CNN&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Faster-rcnn-NIPS2015-detection</title>
    <link href="http://yoursite.com/2019/07/10/faster-rcnn-detection/"/>
    <id>http://yoursite.com/2019/07/10/faster-rcnn-detection/</id>
    <published>2019-07-10T03:16:30.000Z</published>
    <updated>2019-07-10T08:58:28.696Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Faster-rcnn-NIPS2015"><a href="#Faster-rcnn-NIPS2015" class="headerlink" title="Faster-rcnn-NIPS2015"></a>Faster-rcnn-NIPS2015</h2><ul><li>Faster RCNN：Towards Real-Time Object Detection with Region Proposal Networks</li><li>Paper：<a href="https://arxiv.org/abs/1506.01497" target="_blank" rel="noopener">https://arxiv.org/abs/1506.01497</a></li><li>Code ：<a href="https://github.com/chenyuntc/simple-faster-rcnn-pytorch" target="_blank" rel="noopener">https://github.com/chenyuntc/simple-faster-rcnn-pytorch</a></li><li>参考：<a href="https://zhuanlan.zhihu.com/p/32404424" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/32404424</a></li></ul><h2 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h2><ol><li>使用RPN代替了耗时的selective search操作。</li><li>大致过程如下图。<strong>特征提取，RPN提取ROI（二分类+回归），ROI Head（多分类+回归）</strong><br><img src="/2019/07/10/faster-rcnn-detection/main.PNG" alt="main-framework" title="main-framework"></li></ol><a id="more"></a><h2 id="why"><a href="#why" class="headerlink" title="why"></a>why</h2><ol><li>基于<strong>selective search的方法速度太慢</strong>。</li><li><strong>二阶段</strong>（粗细粒度的筛选），可以使得检测的精度极大提升。</li></ol><h2 id="what"><a href="#what" class="headerlink" title="what"></a>what</h2><ol><li>主要贡献在于，使用RPN替代了selective search方法。</li><li>Faster RCNN可主要分为三个阶段。</li></ol><ul><li>阶段一，<strong>特征提取</strong>。</li><li>阶段二，使用<strong>RPN提取ROIs</strong>，并对其中部分样本（256）进行二分类和回归，NMS过滤。</li><li>阶段三，使用<strong>ROI Pooling</strong>，对ROIs中的部分ROI进行Pooling操作统一到相同尺度，在做分类和回归，NMS过滤。</li></ul><h2 id="how"><a href="#how" class="headerlink" title="how"></a>how</h2><ol><li>Faster RCNN主要分三步：特征提取，RPN提取ROIs（<strong>二分类</strong>+回归），ROI Head/Pooling（<strong>多分类</strong>+回归）<br><img src="/2019/07/10/faster-rcnn-detection/network1.jpg" alt="network" title="network"><h3 id="Feature-Extractor"><a href="#Feature-Extractor" class="headerlink" title="Feature Extractor"></a>Feature Extractor</h3></li><li>一般使用与训练好的VGG16，前4层的卷积的学习率设为0（为节省显存），Conv5_3的feature作为输出；VGG最后的三层全连接层的前两层，一般用来初始化RoIHead的部分参数。<br><img src="/2019/07/10/faster-rcnn-detection/VGG2.jpg" alt="VGG16" title="VGG16"><h3 id="RPN"><a href="#RPN" class="headerlink" title="RPN"></a>RPN</h3></li><li>每个位置使用的anchor个数为9个，所以整张图大概会生成20000个anchors。</li><li><strong>RPN结构</strong><br>3x3的卷积不太清楚什么用意？后接两个1x1的卷积分别用于二分类（9x2）和位置回归（9x4）。</li><li><strong>AnchorTargetCreator</strong><br>RPN利用AnchorTargetCreator从20000个anchor中选取256个做分类和回归。</li></ol><ul><li>计算所有anchors与GT的iou，每个GT对应IOU<strong>最高</strong>的anchor作为正样本。</li><li>其余样本随机选择与GT的iou大于阈值0.7的样本作为正样本。</li><li>随机选择与GT的iou小于阈值0.1的样本作为负样本。正负样本的比例大概为1：1，总数为256。</li></ul><ol start="4"><li><strong>ProposalCreator</strong><br>RPN利用ProposalCreator生成ROIs。</li></ol><ul><li>计算20000个anchors属于前景的概率，对应的位置参数</li><li>选取概率较大的12000个anchors，利用回归的位置参数修正这些anchors</li><li>使用NMS，选择出anchors最大的2000个ROIs</li><li>inference时候，12000，2000分别对应6000，300</li></ul><ol start="5"><li><strong>损失计算</strong></li></ol><ul><li>分类损失，使用交叉熵。</li><li>回归损失，使用Smooth L1 loss<br><img src="/2019/07/10/faster-rcnn-detection/RPN.jpg" alt="RPN" title="RPN"><h3 id="ROI-Head-pooling"><a href="#ROI-Head-pooling" class="headerlink" title="ROI Head/pooling"></a>ROI Head/pooling</h3></li></ul><ol><li><strong>ProposalTargetCreator</strong></li></ol><ul><li>ROIs和GT的iou大于0.5的选择32个。</li><li>ROIs和GT的iou小于0/1的选择96个。</li></ul><ol start="2"><li><strong>ROI Pooling</strong><br>在RPN提供的2000个ROIs上，首先使用ProposalTargetCreator挑选128个ROIs，然后使用ROI Pooling将其pooling到统一的尺寸（128x512x7x7，ROI pooling是为了<strong>共享权重</strong>），继续进行分类和回归。FC21用来分类，20+1背景；F84用来回归，21x4。</li><li><strong>损失计算</strong></li></ol><ul><li>分类，交叉熵；回归，Smooth L1 loss</li><li>回归，只对ROI中的正样本计算loss<br><img src="/2019/07/10/faster-rcnn-detection/ROIHead.jpg" alt="ROI Head" title="ROI Head"></li></ul><ol start="4"><li>小结</li></ol><ul><li>RPN阶段是前/背景的二分类，ROIHead是21分类</li><li>RPN阶段，ROIHead阶段都做了NMS</li><li>RPN阶段，ROIHead阶段都进行了回归<h3 id="Loss"><a href="#Loss" class="headerlink" title="Loss"></a>Loss</h3></li></ul><ol><li>4种损失加权求和</li><li>RPN分类/回归损失，ROI分类/回归损失</li></ol><h2 id="result"><a href="#result" class="headerlink" title="result"></a>result</h2><ol><li>mAP为0.699，fps为5<br><img src="/2019/07/10/faster-rcnn-detection/result.PNG" alt="result" title="result"></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;Faster-rcnn-NIPS2015&quot;&gt;&lt;a href=&quot;#Faster-rcnn-NIPS2015&quot; class=&quot;headerlink&quot; title=&quot;Faster-rcnn-NIPS2015&quot;&gt;&lt;/a&gt;Faster-rcnn-NIPS2015&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;Faster RCNN：Towards Real-Time Object Detection with Region Proposal Networks&lt;/li&gt;
&lt;li&gt;Paper：&lt;a href=&quot;https://arxiv.org/abs/1506.01497&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://arxiv.org/abs/1506.01497&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Code ：&lt;a href=&quot;https://github.com/chenyuntc/simple-faster-rcnn-pytorch&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://github.com/chenyuntc/simple-faster-rcnn-pytorch&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;参考：&lt;a href=&quot;https://zhuanlan.zhihu.com/p/32404424&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://zhuanlan.zhihu.com/p/32404424&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;Overview&quot;&gt;&lt;a href=&quot;#Overview&quot; class=&quot;headerlink&quot; title=&quot;Overview&quot;&gt;&lt;/a&gt;Overview&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;使用RPN代替了耗时的selective search操作。&lt;/li&gt;
&lt;li&gt;大致过程如下图。&lt;strong&gt;特征提取，RPN提取ROI（二分类+回归），ROI Head（多分类+回归）&lt;/strong&gt;&lt;br&gt;&lt;img src=&quot;/2019/07/10/faster-rcnn-detection/main.PNG&quot; alt=&quot;main-framework&quot; title=&quot;main-framework&quot;&gt;&lt;/li&gt;
&lt;/ol&gt;
    
    </summary>
    
      <category term="detection" scheme="http://yoursite.com/categories/detection/"/>
    
    
      <category term="detection" scheme="http://yoursite.com/tags/detection/"/>
    
  </entry>
  
  <entry>
    <title>Yolo-v3-CVPR2018-detection</title>
    <link href="http://yoursite.com/2019/07/09/Yolo-v3-detection/"/>
    <id>http://yoursite.com/2019/07/09/Yolo-v3-detection/</id>
    <published>2019-07-09T08:54:47.000Z</published>
    <updated>2019-07-09T10:53:07.513Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Yolo-v3-2018"><a href="#Yolo-v3-2018" class="headerlink" title="Yolo v3-2018"></a>Yolo v3-2018</h2><ul><li>YOLOv3: An Incremental Improvement</li><li>Paper：<a href="https://pjreddie.com/media/files/papers/YOLOv3.pdf" target="_blank" rel="noopener">https://pjreddie.com/media/files/papers/YOLOv3.pdf</a></li><li>Code：<a href="https://github.com/marvis/pytorch-yolo3" target="_blank" rel="noopener">https://github.com/marvis/pytorch-yolo3</a></li></ul><h2 id="why"><a href="#why" class="headerlink" title="why"></a>why</h2><ol><li>针对Yolo v1/2中对<strong>小物体不友好</strong>的问题。</li><li><strong>深层网络</strong>DarkNet-53替换。</li></ol><a id="more"></a><h2 id="what"><a href="#what" class="headerlink" title="what"></a>what</h2><ol><li>使用FPN解决小物体检测问题。</li><li>DarkNet-19 + 残差结构实现深层网络结构替换。</li><li>loss更换。</li></ol><h2 id="how"><a href="#how" class="headerlink" title="how"></a>how</h2><ol><li><strong>FPN</strong><br><img src="/2019/07/09/Yolo-v3-detection/FPN.jpg" alt="FPN" title="FPN"></li></ol><ul><li>Yolo v3在输入为416x416时，使用了3个尺度的特征图，52，26，13，feature map上每个点使用3个先验框，则先使用k-means获取9个box，再将这些box按照尺度大框小，尺度小框大的原则分别分配给3个特征图。</li></ul><ol start="2"><li><strong>Darknet-53</strong><br><img src="/2019/07/09/Yolo-v3-detection/darknet-53.jpg" alt="Darknet-53" title="Darknet-53"></li><li><strong>loss</strong></li></ol><ul><li>损失函数由v2的softmax loss替换为logistic loss</li><li>softmax的<strong>归一化操作</strong>则意味着每个候选框只对应着一个类别，当预测的目标类别很复杂（多个相似类别）的时候，采用logistic regression进行分类，但是可以输出多个分类，比如说，男人，人。</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;Yolo-v3-2018&quot;&gt;&lt;a href=&quot;#Yolo-v3-2018&quot; class=&quot;headerlink&quot; title=&quot;Yolo v3-2018&quot;&gt;&lt;/a&gt;Yolo v3-2018&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;YOLOv3: An Incremental Improvement&lt;/li&gt;
&lt;li&gt;Paper：&lt;a href=&quot;https://pjreddie.com/media/files/papers/YOLOv3.pdf&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://pjreddie.com/media/files/papers/YOLOv3.pdf&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Code：&lt;a href=&quot;https://github.com/marvis/pytorch-yolo3&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://github.com/marvis/pytorch-yolo3&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;why&quot;&gt;&lt;a href=&quot;#why&quot; class=&quot;headerlink&quot; title=&quot;why&quot;&gt;&lt;/a&gt;why&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;针对Yolo v1/2中对&lt;strong&gt;小物体不友好&lt;/strong&gt;的问题。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;深层网络&lt;/strong&gt;DarkNet-53替换。&lt;/li&gt;
&lt;/ol&gt;
    
    </summary>
    
      <category term="detection" scheme="http://yoursite.com/categories/detection/"/>
    
    
      <category term="detection" scheme="http://yoursite.com/tags/detection/"/>
    
  </entry>
  
  <entry>
    <title>Yolo-v2-CVPR17-detection</title>
    <link href="http://yoursite.com/2019/07/09/Yolo-v2-detection/"/>
    <id>http://yoursite.com/2019/07/09/Yolo-v2-detection/</id>
    <published>2019-07-09T01:59:23.000Z</published>
    <updated>2019-07-10T08:43:21.233Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Yolo-v2-2017"><a href="#Yolo-v2-2017" class="headerlink" title="Yolo v2 2017"></a>Yolo v2 2017</h2><ul><li>Yolo-v2（YOLO9000）: Better, Faster, Stronger</li><li>Paper：<a href="https://arxiv.org/abs/1612.08242" target="_blank" rel="noopener">https://arxiv.org/abs/1612.08242</a></li><li>Code: <a href="https://github.com/marvis/pytorch-yolo2" target="_blank" rel="noopener">https://github.com/marvis/pytorch-yolo2</a></li></ul><h2 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h2><ol><li>基于Yolo v1做了诸多改进。针对Yolo v1<strong>定位不精准，召回率低，对小物体不友好的问题，提出了位置限定预测，Anchor+卷积预测，pass-through操作</strong>等。</li><li>同时，引入了<strong>BN，高分辨率输入，边界框聚类分析，darnet-19，多尺度训练</strong>等，提高了检测性能。</li><li>最终在输入为544x544时，VOC07上mAP可达到78.6，相对应的fps为40（不同输入对应不同结果）</li></ol><a id="more"></a><h2 id="why"><a href="#why" class="headerlink" title="why"></a>why</h2><ol><li>Yolo v1虽然检测速度很快，但是<strong>定位精度不准，物体定位不准确，召回率低，对小物体不友好</strong>，精度效果不如RCNN好。</li></ol><h2 id="what"><a href="#what" class="headerlink" title="what"></a>what</h2><p><img src="/2019/07/09/Yolo-v2-detection/compare.jpg" alt="compare" title="compare"></p><ol><li><strong>Batch Normalization</strong></li></ol><ul><li>在Yolo v2中每一个卷积层之后，都添加BN层，抛弃Dropout。</li><li>BN可以提高模型的收敛速度，起到一定的正则化效果，防止模型过拟合。</li><li>使用BN后，mAP提高了2.4%</li></ul><ol start="2"><li><strong>高分辨率输入</strong></li></ol><ul><li>在Yolo v2中，使用448x448高分辨率输入，抛弃224x224低分辨率输入。</li><li>低分辨率不利于检测模型。因为在ImageNet上的预训练模型使用的为224x224的输入，在检测数据上使用448x448进行finetune效果不好；Yolo v2增加了在ImageNet上使用448x448输入来finetune的步骤，使模型可以适应检测数据上的高分辨率输入。</li><li>使用高分辨率后，mAP提高了4%</li></ul><ol start="3"><li><strong>卷积预测+Anchors</strong></li></ol><ul><li>更换FC层预测为Conv预测，同时使用anchor box。</li><li>Yolo v2采用416x416的输入，stride为32，是为了<strong>保证最后feature map的大小为奇数（13x13）</strong>，其包含一个中心点，对于一些大物体，中心点通常落到图片的中心位置，使用feature map中心点去预测这些物体会相对容易。</li><li>Yolo v2对于每一个anchor box都独立预测一套分类概率</li><li>使用anchor之后，召回率提高了7%</li></ul><ol start="4"><li><strong>边界框聚类分析</strong></li></ol><ul><li>Yolo v2使用K-means，对训练集中的边界框使用box与中心box的IOU值作为指标进行聚类分析，改善在Faster RCNN和SSD中人工设定先验框的主观性。Yolo v2最终选取5个聚类中心作为先验框。</li><li>对于不同的数据集可以分析出更合适的先验框尺度，可以更贴近数据集中gt的尺度。</li><li>使用聚类分析后，mAP提高了0.4%</li></ul><ol start="5"><li><strong>DarkNet-19</strong><br><img src="/2019/07/09/Yolo-v2-detection/darknet.jpg" alt="DarkNet-19" title="DarkNet-19"></li></ol><ul><li>使用特征提取网络，抛弃GoogLeNet结构。</li><li>DarkNet-19使用19个卷积层和5个max pool层，使用7个1x1卷积来减少参数/计算量。最后一层使用global avgpooling（滑窗大小=feature map大小）。</li><li>计算量减少33%</li></ul><ol start="6"><li><strong>位置预测限定</strong>   </li></ol><ul><li>沿用Yolo v1的思想，预测边界框中心点相对于对应cell左上角的偏移量，相当于把中心点约束在当前的cell内。抛弃无约束的位置预测。</li><li>其中，bx，by，bw，bh分别为feature map上预测框的中心点坐标和宽高；cx，cy为cell左上角的坐标（每个cell的大小都为1x1）；tx，ty，tw，th分别为预测的坐标偏移量；pw，ph为先验框的宽高；W，H为特征图的大小。img_w，img_h为原始图的宽高。</li><li>边界框的最终位置为：bx / W <em> img_w，by / H </em> img_h，bw / W <em> img_w，bh / H </em> img_h</li><li>使用该约束预测 + 聚类分析，mAP提升5%<br><img src="/2019/07/09/Yolo-v2-detection/loc_pred.jpg" alt="loc-pred" title="loc-pred"></li></ul><ol start="7"><li><strong>pass through层</strong></li></ol><ul><li>pass through层将DarkNet-19中最后一个max pooling层的输入（26x26x256）进行pass through变换操作得到（13x13x2048）,与输出（13x13x1024）进行连接得到（13x13x3072）,然后卷积在该特征图上进行预测。</li><li>该操作使mAP提高了1%<br><img src="/2019/07/09/Yolo-v2-detection/pass-through.jpg" alt="pass-through" title="pass-through"></li></ul><ol start="8"><li><strong>多尺度输入训练</strong></li></ol><ul><li>采用不同大小的图片作为输入，使其可以适应多种大小的图片输入。</li><li>每个10个迭代周期，随机选择一种输入大小（必须为32的倍数，如320，352…608），同时对最后检测层进行修改后训练。<br><img src="/2019/07/09/Yolo-v2-detection/multi-scale.jpg" alt="multi-scale" title="multi-scale"></li></ul><h2 id="how"><a href="#how" class="headerlink" title="how"></a>how</h2><ol><li><strong>训练过程</strong></li></ol><ul><li>阶段一，使用输入大小为224x224，在ImageNet分类数据集上对DarkNet-19进行预训练。</li><li>阶段二，调整输入大小为448x448，继续在ImageNet分类数据集上对DarkNet-19进行fine-tune。</li><li>阶段三，修改分类模型为检测模型，在检测数据集上进行fine-tune。网络修改包括（网路结构可视化）：移除最后一个卷积层、global avgpooling层以及softmax层，并且新增了三个 3x3卷积层，同时增加了一个passthrough层，最后使用1x1卷积层输出预测结果。</li></ul><ol start="2"><li><strong>损失函数</strong><br><img src="/2019/07/09/Yolo-v2-detection/loss.jpg" alt="loss" title="loss"></li></ol><ul><li>第一部分为，背景（iou小于设定阈值）的置信度误差。</li><li>第二部分为，先验框与预测框的坐标误差，只在前12800次迭代中计算。</li><li>第三部分为，计算与gt匹配的预测框的各部分的loss，坐标误差，置信度误差，分类误差。一个gt只匹配一个预测框，其余的大于iou阈值的预测框的loss不计算。而且Yolo v1中使用平方根降低box大小对loss的影响，Yolo v2使用权重稀系数来控制loss，尺度小一些的box的权重高一些。</li></ul><ol start="3"><li>总结</li></ol><ul><li>加了很多其他文章的点，性能提升很多，但是对小物体不友好的情况仍然没有改善。</li></ul><h2 id="Yolo9000"><a href="#Yolo9000" class="headerlink" title="Yolo9000"></a>Yolo9000</h2><ol><li>提出了一种<strong>分类和检测联合训练策略</strong>。对于检测数据集，可以用来学习预测物体的边界框、置信度以及为物体分类，而对于分类数据集可以仅用来学习分类，但是其可以大大扩充模型所能检测的物体种类。</li><li>因为检测和分类两者类别并不完全互斥，所以作者提出了一种层级分类方法。即根据各个类别之间的从属关系立一种树结构WordTree。</li><li>WordTree中的根节点为”physical object”，每个节点的子节点都属于同一子类，可以对它们进行softmax处理。在给出某个类别的预测概率时，需要找到其所在的位置，遍历这个path，然后计算path上各个节点的概率之积。</li><li>在<strong>训练</strong>时，如果是检测样本，按照YOLOv2的loss计算误差，而对于分类样本，只计算分类误差。在<strong>预测</strong>时，YOLOv2给出的置信度，边界框位置，一个树状概率图。在这个概率图中找到概率最高的路径，当达到某一个阈值时停止，就用当前节点表示预测的类别。<br><img src="/2019/07/09/Yolo-v2-detection/wordtree.jpg" alt="wordtree" title="wordtree"></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;Yolo-v2-2017&quot;&gt;&lt;a href=&quot;#Yolo-v2-2017&quot; class=&quot;headerlink&quot; title=&quot;Yolo v2 2017&quot;&gt;&lt;/a&gt;Yolo v2 2017&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;Yolo-v2（YOLO9000）: Better, Faster, Stronger&lt;/li&gt;
&lt;li&gt;Paper：&lt;a href=&quot;https://arxiv.org/abs/1612.08242&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://arxiv.org/abs/1612.08242&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Code: &lt;a href=&quot;https://github.com/marvis/pytorch-yolo2&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://github.com/marvis/pytorch-yolo2&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;Overview&quot;&gt;&lt;a href=&quot;#Overview&quot; class=&quot;headerlink&quot; title=&quot;Overview&quot;&gt;&lt;/a&gt;Overview&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;基于Yolo v1做了诸多改进。针对Yolo v1&lt;strong&gt;定位不精准，召回率低，对小物体不友好的问题，提出了位置限定预测，Anchor+卷积预测，pass-through操作&lt;/strong&gt;等。&lt;/li&gt;
&lt;li&gt;同时，引入了&lt;strong&gt;BN，高分辨率输入，边界框聚类分析，darnet-19，多尺度训练&lt;/strong&gt;等，提高了检测性能。&lt;/li&gt;
&lt;li&gt;最终在输入为544x544时，VOC07上mAP可达到78.6，相对应的fps为40（不同输入对应不同结果）&lt;/li&gt;
&lt;/ol&gt;
    
    </summary>
    
      <category term="detection" scheme="http://yoursite.com/categories/detection/"/>
    
    
      <category term="detection" scheme="http://yoursite.com/tags/detection/"/>
    
  </entry>
  
  <entry>
    <title>SSD-CVPR15-detection</title>
    <link href="http://yoursite.com/2019/07/08/SSD-detection/"/>
    <id>http://yoursite.com/2019/07/08/SSD-detection/</id>
    <published>2019-07-08T08:39:15.000Z</published>
    <updated>2019-07-09T08:34:06.481Z</updated>
    
    <content type="html"><![CDATA[<h1 id="SSD-2015"><a href="#SSD-2015" class="headerlink" title="SSD - 2015"></a>SSD - 2015</h1><ul><li>SSD: Single Shot MultiBox Detector</li><li>Paper：<a href="https://arxiv.org/pdf/1611.10012.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1611.10012.pdf</a> </li><li>Code：<a href="https://github.com/amdegroot/ssd.pytorch" target="_blank" rel="noopener">https://github.com/amdegroot/ssd.pytorch</a></li></ul><h2 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h2><ol><li>SSD与Yolo v1的对比</li></ol><ul><li><strong>卷积检测</strong>。抛弃FC层采用卷积做检测。SSD每个检测框都对应输出一套独立的检测值。</li><li><strong>多尺度特征图</strong>。采用多尺度特征图，大尺度检测小物体，小尺度检测大物体。</li><li><strong>先验框</strong>。采用不同尺度/长宽比的先验框。</li></ul><ol start="2"><li>速度：58fps。mAP为72.1</li></ol><a id="more"></a><h2 id="why"><a href="#why" class="headerlink" title="why"></a>why</h2><ol><li>针对Yolo v1存在的定位不精准，对小物体不友好等缺点的改进。</li></ol><h2 id="what"><a href="#what" class="headerlink" title="what"></a>what</h2><ol><li>one-stage检测。均匀地在图像上的不同位置，使用不同的尺度/长宽比进行采样，然后使用CNN提取特征后直接进行分类和回归。</li><li>SSD结合了卷积预测，多尺度特征，先验框来改进Yolo v1中存在的缺点。</li></ol><h2 id="how"><a href="#how" class="headerlink" title="how"></a>how</h2><ol><li><strong>网络结构</strong></li></ol><ul><li><strong>输入</strong>：300x300/512x512</li><li><strong>网络结构</strong><br>①主干网络使用VGG16，分别将VGG16的全连接层fc6和fc7转换成conv6和conv7，移除dropout和fc8层，并增加了卷积层来获得更多的feature map。<br>②Conv6使用扩展卷积，来扩大卷积的感受野。Conv6采用3x3大小但dilation rate=6的扩展卷积。<br>③使用feature map大小分别为38，19，10，5，3，1。不同feature map上设定的先验框数目不同，分别为4，6，6，4，4。<br>④随着特征图大小降低，先验框尺度线性增加。长宽比一般选取{1,2,3,1/2,1/3}<br><img src="/2019/07/08/SSD-detection/network.jpg" alt="network" title="network"></li><li><strong>输出</strong><br>①检测值包含两个部分：类别置信度和边界框位置，各采用一次3x3卷积来进行完成。令nk为该特征图所采用的先验框数目，那么类别置信度需要的卷积核数量为nk x C ，而边界框位置需要的卷积核数量为nk x 4。<br>②各个feature map对应：w x h x nk x (C+4)</li><li><strong>GT</strong><br><img src="/2019/07/08/SSD-detection/gt.PNG" alt="GT" title="GT"></li></ul><ol start="2"><li><strong>损失函数</strong></li></ol><ul><li>位置损失 + 置信度损失。其中N为正样本数，<br><img src="/2019/07/08/SSD-detection/loss.PNG" alt="loss" title="loss"></li><li>位置损失<br><img src="/2019/07/08/SSD-detection/loss_loc.PNG" alt="loss_loc" title="loss_loc"></li><li>置信度损失 - softmax loss<br><img src="/2019/07/08/SSD-detection/loss_conf.jpg" alt="loss_conf" title="loss_conf"></li></ul><ol start="3"><li><strong>训练细节</strong></li></ol><ul><li>先验框匹配<br>①Yolo是gt所在单元格中与其IOU最大的那个作匹配。<br>②第一步，SSD是找到每个gt与其最大的IOU作匹配，保证每一个gt都一定有一个先验框与之匹配。将匹配的bbox作为正样本，其余为负样本。第二步，将剩余先验框中与gts的iou大于阈值的进行匹配。匹配成功的都是正样本。<br>③再采用hard negative mining，对负样本按照<strong>背景</strong>置信度误差进行抽样，选取误差最大的topk个，保证正负样本的比例为1：3。   </li><li>使用了数据增强。裁剪，旋转，扭曲，随机采样等等。</li></ul><h2 id="result"><a href="#result" class="headerlink" title="result"></a>result</h2><ol><li>数据增强，可以提高9个百分点（65.6 - 74.3）。</li><li>多尺度检测，可以提高12个百分点（62.4 - 74.6）。</li></ol>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;SSD-2015&quot;&gt;&lt;a href=&quot;#SSD-2015&quot; class=&quot;headerlink&quot; title=&quot;SSD - 2015&quot;&gt;&lt;/a&gt;SSD - 2015&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;SSD: Single Shot MultiBox Detector&lt;/li&gt;
&lt;li&gt;Paper：&lt;a href=&quot;https://arxiv.org/pdf/1611.10012.pdf&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://arxiv.org/pdf/1611.10012.pdf&lt;/a&gt; &lt;/li&gt;
&lt;li&gt;Code：&lt;a href=&quot;https://github.com/amdegroot/ssd.pytorch&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://github.com/amdegroot/ssd.pytorch&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;Overview&quot;&gt;&lt;a href=&quot;#Overview&quot; class=&quot;headerlink&quot; title=&quot;Overview&quot;&gt;&lt;/a&gt;Overview&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;SSD与Yolo v1的对比&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;卷积检测&lt;/strong&gt;。抛弃FC层采用卷积做检测。SSD每个检测框都对应输出一套独立的检测值。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;多尺度特征图&lt;/strong&gt;。采用多尺度特征图，大尺度检测小物体，小尺度检测大物体。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;先验框&lt;/strong&gt;。采用不同尺度/长宽比的先验框。&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start=&quot;2&quot;&gt;
&lt;li&gt;速度：58fps。mAP为72.1&lt;/li&gt;
&lt;/ol&gt;
    
    </summary>
    
      <category term="detection" scheme="http://yoursite.com/categories/detection/"/>
    
    
      <category term="detection" scheme="http://yoursite.com/tags/detection/"/>
    
  </entry>
  
  <entry>
    <title>Yolo-v1-CVPR2015-detection</title>
    <link href="http://yoursite.com/2019/07/08/Yolo-v1-detection/"/>
    <id>http://yoursite.com/2019/07/08/Yolo-v1-detection/</id>
    <published>2019-07-08T07:26:29.000Z</published>
    <updated>2019-07-10T12:42:02.799Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Yolo-v1-2015"><a href="#Yolo-v1-2015" class="headerlink" title="Yolo v1 - 2015"></a>Yolo v1 - 2015</h2><ul><li>Yolo-v1：You Only Look Once, Unified, Real-Time Object Detection.</li><li>Paper：<a href="https://arxiv.org/abs/1506.02640" target="_blank" rel="noopener">https://arxiv.org/abs/1506.02640</a></li><li>Code: <a href="https://github.com/gliese581gg/YOLO_tensorflow" target="_blank" rel="noopener">https://github.com/gliese581gg/YOLO_tensorflow</a></li></ul><h2 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h2><ol><li>经典的one-stage。直接对原图进行网格划分，将原图分为nxn的小块，然后通过卷积产生nxn的特征图，其一一对应，feature map上每个元素预测对应单元格内的分类/置信度/bbox偏移。</li><li>速度：155fps，mAP：63.4</li></ol><a id="more"></a><h2 id="why"><a href="#why" class="headerlink" title="why"></a>why</h2><ol><li>DPM采用不同大小和比例（宽高比）的窗口在整张图片上以一定的步长进行滑动，然后对这些窗口对应的区域做图像分类，来实现对整张图片的检测。DPM的缺点，目标大小未知，需要使用不同的大小/比例，步长，计算量很大。</li><li>RCNN使用selective search的方法仍然耗时。</li></ol><h2 id="what"><a href="#what" class="headerlink" title="what"></a>what</h2><ol><li>Yolo直接将image分成nxn的网格，然后根据卷积生成相同大小的feature map，feature map上每个元素预测对应单元格内的分类/置信度/bbox偏移。</li></ol><h2 id="how"><a href="#how" class="headerlink" title="how"></a>how</h2><ol><li><strong>网络结构</strong></li></ol><ul><li>输入：448x448的image<br> 划分为7x7的网格。</li><li>网络结构<br>backbone：使用了24个卷积层，2个fc层<br><img src="/2019/07/08/Yolo-v1-detection/network.jpg" alt="network" title="network"><br>训练过程中的网络结构。在googLenet之后添加了4个随机初始化权重的Conv层和2个fc层。<br><img src="/2019/07/08/Yolo-v1-detection/train.jpg" alt="train" title="train"></li><li>输出：7x7x30<br>  其中30为20个类别概率，2个置信度，2个bbox的(x,y,w,h),其中，预测的x,y是中心坐标相对于左上角坐标的偏移量，单位是相对于单元格大小的；w，h是相对于整个图片的宽和高的比例；所以xy在[0,1]范围内。<br>  预测tensor示意图。网络计算量：SxSx(Bx5+C)<br><img src="/2019/07/08/Yolo-v1-detection/predict.jpg" alt="predict" title="predict"></li></ul><ol start="2"><li><strong>损失函数</strong></li></ol><ul><li>采用MSE损失函数，对于定位损失，分类损失分别采用不同的权重。定位损失使用较大的权重（5），然后分类损失权重分别为（0.5无object，1有object）。</li><li>其中，要各个大小bbox要同等对待，但是较小的边界框的误差更敏感，所以将网络bbox的w,h的预测改为了对其平方根的预测。<br><img src="/2019/07/08/Yolo-v1-detection/loss.jpg" alt="loss" title="loss"></li></ul><h2 id="result"><a href="#result" class="headerlink" title="result"></a>result</h2><ol><li><strong>优点</strong></li></ol><ul><li>简洁，速度较快，可以达到155fps，mAP为63.4</li><li>对整个image做conv，不容易对背景误判</li></ul><ol start="2"><li><strong>缺点</strong></li></ol><ul><li>每个单元格仅预测两个bbox，且共享一个类别，所以对密集物体判别不好。</li><li>定位不精准。</li><li>对小物体不友好，且无法定位比例不同寻常的物体。</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;Yolo-v1-2015&quot;&gt;&lt;a href=&quot;#Yolo-v1-2015&quot; class=&quot;headerlink&quot; title=&quot;Yolo v1 - 2015&quot;&gt;&lt;/a&gt;Yolo v1 - 2015&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;Yolo-v1：You Only Look Once, Unified, Real-Time Object Detection.&lt;/li&gt;
&lt;li&gt;Paper：&lt;a href=&quot;https://arxiv.org/abs/1506.02640&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://arxiv.org/abs/1506.02640&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Code: &lt;a href=&quot;https://github.com/gliese581gg/YOLO_tensorflow&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://github.com/gliese581gg/YOLO_tensorflow&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;Overview&quot;&gt;&lt;a href=&quot;#Overview&quot; class=&quot;headerlink&quot; title=&quot;Overview&quot;&gt;&lt;/a&gt;Overview&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;经典的one-stage。直接对原图进行网格划分，将原图分为nxn的小块，然后通过卷积产生nxn的特征图，其一一对应，feature map上每个元素预测对应单元格内的分类/置信度/bbox偏移。&lt;/li&gt;
&lt;li&gt;速度：155fps，mAP：63.4&lt;/li&gt;
&lt;/ol&gt;
    
    </summary>
    
      <category term="detection" scheme="http://yoursite.com/categories/detection/"/>
    
    
      <category term="detection" scheme="http://yoursite.com/tags/detection/"/>
    
  </entry>
  
  <entry>
    <title>offer-plan</title>
    <link href="http://yoursite.com/2019/07/08/offer-plan/"/>
    <id>http://yoursite.com/2019/07/08/offer-plan/</id>
    <published>2019-07-08T02:41:18.000Z</published>
    <updated>2019-07-21T13:36:41.103Z</updated>
    
    <content type="html"><![CDATA[<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script><div id="hbe-security">  <div class="hbe-input-container">  <input type="password" class="hbe-form-control" id="pass" placeholder="Please enter the password to read the blog." />    <label for="pass">Please enter the password to read the blog.</label>    <div class="bottom-line"></div>  </div></div><div id="decryptionError" style="display: none;">Incorrect Password!</div><div id="noContentError" style="display: none;">No content to display!</div><div id="encrypt-blog" style="display:none">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</div><script src="/lib/crypto-js.js"></script><script src="/lib/blog-encrypt.js"></script><link href="/css/blog-encrypt.css" rel="stylesheet" type="text/css">]]></content>
    
    <summary type="html">
    
      The article has been encrypted, please enter your password to view.&lt;br&gt;
    
    </summary>
    
      <category term="plan" scheme="http://yoursite.com/categories/plan/"/>
    
    
      <category term="plan" scheme="http://yoursite.com/tags/plan/"/>
    
  </entry>
  
  <entry>
    <title>python内存管理</title>
    <link href="http://yoursite.com/2019/07/07/python%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/"/>
    <id>http://yoursite.com/2019/07/07/python内存管理/</id>
    <published>2019-07-07T07:36:25.000Z</published>
    <updated>2019-07-08T02:41:45.931Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Python内存管理"><a href="#Python内存管理" class="headerlink" title="Python内存管理"></a>Python内存管理</h1><ul><li>今天在刷复杂链表复制的时候，碰到了这个点，总结一下</li><li>python内存管理机制：引用计数，垃圾回收，内存池机制</li></ul><a id="more"></a><h2 id="引用计数"><a href="#引用计数" class="headerlink" title="引用计数"></a>引用计数</h2><ol><li>python中，对象和引用分离，对于<strong>整数int和短小的字符str</strong>，python都会缓</li><li>存这些对象，用以重复使用，当创建多个相同的对象时，实际上只是让所有这些引用指向同一个对象。</li></ol><ul><li>int：-5~256</li><li>str：只包含数字和字母的元素有小数据池 + 单个字母*int（21）存在小数据池<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">a = <span class="number">1</span> </span><br><span class="line">b = <span class="number">1</span></span><br><span class="line">id(a) == id(b) <span class="comment"># True 即a，b为1对象的两个引用。</span></span><br><span class="line">a <span class="keyword">is</span> b <span class="comment"># True 用于判断两个引用指向的对象是否相同</span></span><br><span class="line">getrefcount(a) <span class="comment"># 判断对象的引用总数，getrefcount会创建一个临时引用，这样会比期望结果多1</span></span><br></pre></td></tr></table></figure></li></ul><ol start="2"><li>长字符串和其他对象可以有多个相同的对象，可以使用赋值语句创造出新的对象.</li><li>对象引用对象。例如list,dict等可以包含多个对象，实际上，其中包含的是各个元素对象的引用。</li><li>引用减少。可以使用del关键字来删除某个引用，或者引用重定向时，原对象的引用数会减少。</li><li>可能会出现引用环问题。python通过对每个对象i引用计数，并会遍历所有对象i，对于每个对象i引用的对象j，将j相应的引用计数减1。然后python会将引用计数为0的回收。</li></ol><h2 id="垃圾回收"><a href="#垃圾回收" class="headerlink" title="垃圾回收"></a>垃圾回收</h2><ol><li>在python中，当某一对象的引用计数为0时，将会被回收。但是python不会频繁地进行垃圾回收，因为会大大影响python的工作效率，python只会在特定的条件下，自动启动垃圾回收（python运行时，会自动记录其中分配对象和取消分配对象的次数，当两者的差值大于某阈值时，垃圾回收便会启动）。<ul><li>gc.getthreshold()，可以查看垃圾回收启动的阈值。</li></ul></li><li>分代回收</li></ol><ul><li>理解：存活时间越久的对象，越不可能成为垃圾，python会减少这些对象的使用频率。</li><li>分代：0，1，2</li><li>0代为新建的对象，0代对象每次都会扫描。在0代对象扫描一定次数后，开始扫描1代对象。在1代对象扫描一定次数后，开始扫描2代对象。</li></ul><h2 id="内存池机制"><a href="#内存池机制" class="headerlink" title="内存池机制"></a>内存池机制</h2><ol><li>python中有大内存和小内存。大内存使用malloc分配，小内存使用内存池分配。</li><li>python内存池机制<ul><li>最上层(3)，用户对python对象直接操作</li><li>中间层(1,2)，内存池，分配256k及以下的内存。malloc分配内存，free不会释放内存，以方便下次使用。</li><li>在下层(0)，分配大于256k的内存，malloc分配内存，free释放内存</li><li>最小层(-1,-2)，有操作系统调用</li></ul></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;Python内存管理&quot;&gt;&lt;a href=&quot;#Python内存管理&quot; class=&quot;headerlink&quot; title=&quot;Python内存管理&quot;&gt;&lt;/a&gt;Python内存管理&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;今天在刷复杂链表复制的时候，碰到了这个点，总结一下&lt;/li&gt;
&lt;li&gt;python内存管理机制：引用计数，垃圾回收，内存池机制&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
      <category term="python" scheme="http://yoursite.com/categories/python/"/>
    
    
      <category term="python" scheme="http://yoursite.com/tags/python/"/>
    
  </entry>
  
  <entry>
    <title>SPM-CVPR19-Tracking</title>
    <link href="http://yoursite.com/2019/06/28/SPM-CVPR2019/"/>
    <id>http://yoursite.com/2019/06/28/SPM-CVPR2019/</id>
    <published>2019-06-28T10:36:36.000Z</published>
    <updated>2019-07-01T14:48:23.644Z</updated>
    
    <content type="html"><![CDATA[<h1 id="SPM"><a href="#SPM" class="headerlink" title="SPM"></a>SPM</h1><ul><li>SPM-Tracker: Series-ParallelMatchingforReal-TimeVisualObjectTracking</li><li>Paper:</li><li>Code:</li></ul><h2 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h2><ol><li>将Tracking中的两个需求（Robustness，deiscrimination）分别放在两个阶段（two-stage：CM-&gt;FM）实现。</li><li>感觉效果惊人！OTB-100上的AUC为0.687，VOT-16上的EAO竟然达到了0.434，GPU上的fps为120，牛！</li><li>抓住了siamese网络的缺点(相似物体容易drift)，解决方式就是在一阶段CM提取目标物体和其相似物体作为正样本，在二阶段FM在仔细区分object和其相似物体，也算是在image中尽可能多的提炼信息。</li></ol><a id="more"></a><h2 id="why"><a href="#why" class="headerlink" title="why"></a>why</h2><ol><li>在tracking的过程中，既要求tracker有足够的判别力(针对相似物体或者相似背景等)，又需要足够的鲁棒性(对于物体的形变，光照等)。但是用一阶段的方法学习两种能力，其间会相互影响。</li><li>现存的tracker速度太慢。</li></ol><h2 id="what"><a href="#what" class="headerlink" title="what"></a>what</h2><ol><li>将Tracking分为两阶段来做，分别是CM，FM。CM负责鲁棒性，FM负责判别力。两阶段的融合省去了做多尺度测试。</li><li>在CM阶段同一类物体都被作为同一物体，来提高CM的鲁棒性。在FM阶段通过距离学习子网络替代了cross corrrelation来提高网络的判别力。CM的输出作为FM的输入，最终的输出是两阶段的融合。</li><li>SPM的优势<ul><li>two-stage，容易train</li><li>CM的输出作为FM的输入，正负样本的比例和难样本得到了平衡</li><li>两个阶段输出的融合可以有更高的精度</li><li>FM阶段有较少的proposals，省去了cross-correlation操作，改为使用trainable distance measure</li></ul></li></ol><h2 id="how"><a href="#how" class="headerlink" title="how"></a>how</h2><p><img src="/2019/06/28/SPM-CVPR2019/framework.PNG" alt="网络结构" title="网络结构"></p><ol><li>网络结构<ul><li>特征提取：Siamese Alexnet(在ImageNet上预训练)</li><li>CM Stage使用SiamRPN的网络结构，最小化类内特性，专注于robust</li><li>ROI Align用来为每个proposal生成固定长度的区域特征</li><li>FM Stage为距离学习网络，最大化不同物体间的特性，专注于discrimination</li><li>最终输出为两阶段decision的融合(score + bbox deltas)</li></ul></li><li>CM阶段<br><img src="/2019/06/28/SPM-CVPR2019/CM.PNG" alt="CM_stage" title="CM"><ul><li>将image中同类物体的<strong>中心区域（红，绿）</strong>都作为正样本，蓝色区域为忽略区域</li></ul></li><li>FM阶段<ul><li>该阶段的重点在于将CM阶段过滤后的object与背景/相似物体区分开   </li><li>经CM过滤后剩余较少的proposal，所以丢弃了cross correlation操作，使用了新的关系网络来进行距离计算。</li><li><ul><li>对于每一个proposal，直接从feature map上crop然后使用ROI pooling生成固定大小的feature，同时将高低层的信息concatenation。</li></ul></li><li>关系网络的输入是图像对concatenate的feature信息，后接1x1卷积，再接2个全连接层（256个neurons），用来cls和box regression</li></ul></li><li>融合<ul><li>最终CM,FM阶段的scores和bbox deltas进行加权融合</li></ul></li></ol><h2 id="other-points"><a href="#other-points" class="headerlink" title="other points"></a>other points</h2><ol><li>CF-based执行必不可少的是在线更新策略，但是结合deep learning是特别慢的，所以researcher使用static discriminative trackers，像siamFC等。</li><li>SiamRPN使用RPN在提高bbox regression方面做了改进，DaSiamRPN使用样本策略(相似的同类物体作为正样本提高robust，语义信息接近的不同类物体作为负样本提高distrimination)在discrimination方面做了提升。</li><li>网络细节<ul><li>在使用的AlexNet中保留了padding，因为ROI align需要feature和source image的像素对齐。</li><li>CM阶段使用no padding的中心feature(应该是从padding后的feature上crop下来)</li><li>每个ROI pooling后的feature大小为6x6x640</li></ul></li><li>train细节<ul><li>IOU 大于0.6，小于0.3的样本被保留。</li><li>loss :两个阶段，四个loss的加权和， cls : cross entropy , reg : smooth l1 loss</li></ul></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;SPM&quot;&gt;&lt;a href=&quot;#SPM&quot; class=&quot;headerlink&quot; title=&quot;SPM&quot;&gt;&lt;/a&gt;SPM&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;SPM-Tracker: Series-ParallelMatchingforReal-TimeVisualObjectTracking&lt;/li&gt;
&lt;li&gt;Paper:&lt;/li&gt;
&lt;li&gt;Code:&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;Overview&quot;&gt;&lt;a href=&quot;#Overview&quot; class=&quot;headerlink&quot; title=&quot;Overview&quot;&gt;&lt;/a&gt;Overview&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;将Tracking中的两个需求（Robustness，deiscrimination）分别放在两个阶段（two-stage：CM-&amp;gt;FM）实现。&lt;/li&gt;
&lt;li&gt;感觉效果惊人！OTB-100上的AUC为0.687，VOT-16上的EAO竟然达到了0.434，GPU上的fps为120，牛！&lt;/li&gt;
&lt;li&gt;抓住了siamese网络的缺点(相似物体容易drift)，解决方式就是在一阶段CM提取目标物体和其相似物体作为正样本，在二阶段FM在仔细区分object和其相似物体，也算是在image中尽可能多的提炼信息。&lt;/li&gt;
&lt;/ol&gt;
    
    </summary>
    
      <category term="papers" scheme="http://yoursite.com/categories/papers/"/>
    
    
      <category term="Tracking" scheme="http://yoursite.com/tags/Tracking/"/>
    
  </entry>
  
  <entry>
    <title>Deepsort-tracking</title>
    <link href="http://yoursite.com/2019/06/25/DeepSort-CVPR2017/"/>
    <id>http://yoursite.com/2019/06/25/DeepSort-CVPR2017/</id>
    <published>2019-06-25T02:36:46.000Z</published>
    <updated>2019-07-02T00:36:32.367Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Deep-Sort-待完善"><a href="#Deep-Sort-待完善" class="headerlink" title="Deep Sort(待完善)"></a>Deep Sort(待完善)</h1><h2 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h2><ol><li>在Sort的基础上整合了appearance信息，引入了深度信息</li><li>将计算复杂度较高放在了离线预训练阶段，在大规模reid的数据集上学习一个关联矩阵，在online阶段，在visual appearance阶段建立了一个mearsure to track的最近邻查询。</li><li>减少了ID switch</li></ol><a id="more"></a><h2 id="Sort-with-Deep-Association-Metric"><a href="#Sort-with-Deep-Association-Metric" class="headerlink" title="Sort with Deep Association Metric"></a>Sort with Deep Association Metric</h2><h3 id="跟踪处理-状态估计"><a href="#跟踪处理-状态估计" class="headerlink" title="跟踪处理 + 状态估计"></a>跟踪处理 + 状态估计</h3><ol><li>使用八个维度值(cx，cy，r，h，vcx，vcy，vr，vh)来估计tracking的状态，同时假设kalman filter是恒定速度和线性观测模型。</li><li>对于每一个track，都要计算上次匹配成功后的帧数a。当再次关联的时候置为0，目的是通过计数找出目标消失的情况。当a &gt; 设定Aage时，我们认为该track在image中消失。对于未关联的detection，我们认为其为新出现的目标。这些目标在前3帧中被认为暂定状态，当这些新出现的track在他们出现的前三帧中未成功关联就被删除。</li></ol><h3 id="匹配问题"><a href="#匹配问题" class="headerlink" title="匹配问题"></a>匹配问题</h3><ol><li>在kalman filter预测和detection状态之间的分配问题一般使用Hungarian算法。<strong>文章中在这里整合了运动信息，外观特征信息</strong>。</li><li>运动信息，通过计算kalman states和detection之间的马氏距离。<strong>这里有公式d(1)(i,j) = (dj −yi)T^Si−1(dj −yi)</strong>。马氏距离通过测量检测远离平均轨道位置的标准偏差的多少来考虑状态估计不确定性。之后通过x2分布来过滤一些不可能存在的关联，<strong>这里有公式b(1) i,j = 1[d(1)(i,j) ≤ t(1)]</strong>。其中的Mahalanobis的阈值t(1)设定为9.4877。</li></ol><ul><li>[注]以上的马氏距离可以无相机运动的时有较好的预测效果。但是在相机快速运动，遮挡的情况下，Mahalanobis距离相当不准确。</li></ul><ol start="3"><li>外观特征，对于每一个detection dj提取外观特征，表示为rj，且||rj|| = 1，我们为每一个track维护它的最近Lk = 100个特征。第二个度量是计算track_i和detection_j在外观特征上的cosine distance。之后再通过x2分布进行过滤。</li></ol><ul><li>[注]同一物体在不同image中生成的feature向量的余弦距离是很小的。</li></ul><ol start="4"><li>lamda*运动信息 + (1-lamda)外观特征。运动信息适合短期预测，外观特征适合长期预测。在paper中，将lamda设为0，但是mahalanobis gate仍然被用来判断不可行的预测结果。</li></ol><h3 id="级联匹配"><a href="#级联匹配" class="headerlink" title="级联匹配"></a>级联匹配</h3><ol><li>原因：在物体长时间遮挡的情况下，kalman预测会增加物体位置预测的不确定性。概率会在状态空间发散，可能无法观察。且当两个track被关联为同一个detection，mahalanobis distance偏向于不确定性更大的track，因为它有效地减少了任何检测的标准偏差与投影轨道平均值之间的距离。<br>因此，采用级联的方式设定优先级。</li><li>级联匹配，优先考虑最小age的track。</li><li>在最终的match阶段，统计未确认，和age为1的未匹配的track。这个操作有助于对突然的外观变化等增加一定的鲁棒性。</li></ol><h3 id="深度外观描述子"><a href="#深度外观描述子" class="headerlink" title="深度外观描述子"></a>深度外观描述子</h3><ol><li>使用最近邻查询，所以要提取较好的具有判别力的特征。文章中使用CNN在大规模的reid数据集上进行训练。</li><li>CNN网络结构使用resnet，两个conv layer加六个res blocks。最后在dense layer计算出来128维的特征映射。</li></ol>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;Deep-Sort-待完善&quot;&gt;&lt;a href=&quot;#Deep-Sort-待完善&quot; class=&quot;headerlink&quot; title=&quot;Deep Sort(待完善)&quot;&gt;&lt;/a&gt;Deep Sort(待完善)&lt;/h1&gt;&lt;h2 id=&quot;Overview&quot;&gt;&lt;a href=&quot;#Overview&quot; class=&quot;headerlink&quot; title=&quot;Overview&quot;&gt;&lt;/a&gt;Overview&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;在Sort的基础上整合了appearance信息，引入了深度信息&lt;/li&gt;
&lt;li&gt;将计算复杂度较高放在了离线预训练阶段，在大规模reid的数据集上学习一个关联矩阵，在online阶段，在visual appearance阶段建立了一个mearsure to track的最近邻查询。&lt;/li&gt;
&lt;li&gt;减少了ID switch&lt;/li&gt;
&lt;/ol&gt;
    
    </summary>
    
      <category term="papers" scheme="http://yoursite.com/categories/papers/"/>
    
    
      <category term="Tracking" scheme="http://yoursite.com/tags/Tracking/"/>
    
  </entry>
  
  <entry>
    <title>C-RPN-CVPR19-tracking</title>
    <link href="http://yoursite.com/2019/06/23/C-RPN-CVPR2019/"/>
    <id>http://yoursite.com/2019/06/23/C-RPN-CVPR2019/</id>
    <published>2019-06-23T02:36:46.000Z</published>
    <updated>2019-07-02T00:36:25.575Z</updated>
    
    <content type="html"><![CDATA[<h1 id="C-RPN"><a href="#C-RPN" class="headerlink" title="C-RPN"></a>C-RPN</h1><ul><li>Siamese Cascaded Region Proposal Networks for Real-Time Visual Tracking</li><li>Paper:</li><li>Code:</li></ul><h2 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h2><ol><li>通过级联RPN（多stages）筛选，解决了样本不平衡问题。(多阶段筛选)</li><li>构建FTB block用于高/低特征融合，结果更加精确。（多层融合）</li><li>其实跟SPM Tracker的出发点相同，都是针对Siamese网络中相似物体的drift问题，解决思想也相同，都是使用多stages过滤以获得更好的效果，但是整体来说效果离SPM差很多，首先多RPN肯定很耗时，FPS在36左右，同时精度提升也不是特别明显，VOT16上EAO为0.363。</li></ol><a id="more"></a><h2 id="why"><a href="#why" class="headerlink" title="why"></a>why</h2><ol><li>针对Siamese自身存在的问题 – 相似物体的drift<ul><li>样本不平衡问题</li><li>大多数样本为简单负样本</li></ul></li><li>在现有的siamese网络中，低层的feature信息没有合理利用<ul><li>高层的信息可能包含更多的语义信息，造成相似物体的drift</li></ul></li></ol><h2 id="what"><a href="#what" class="headerlink" title="what"></a>what</h2><ol><li>提出级联RPN的网络结构，分为3个stages，每个stage都做分类和回归对上一阶筛选的proposals在进行refine，每个阶段都会逐渐过滤简单负样本，保留为下一个阶段保留难例负样本。</li><li>用FTB做高低特征融合。</li></ol><h2 id="how"><a href="#how" class="headerlink" title="how"></a>how</h2><ol><li>网络结构如图。仍然使用AlexNet结构提取特征。<br><img src="/2019/06/23/C-RPN-CVPR2019/Network.PNG" alt="网络结构" title="Network">   </li><li>FTB结构如图。高层feature经过反卷积恢复尺度，然后与底层feature通过element-wise结合，最后对融合后的feature进行插值操作，为了确保最终所有的RPN都能对应相同的GT。<br><img src="/2019/06/23/C-RPN-CVPR2019/FTB.PNG" alt="FTB" title="FTB">   </li><li>GT和各阶段RPN的计算。<br><img src="/2019/06/23/C-RPN-CVPR2019/GT.PNG" alt="GT" title="GT"><br><img src="/2019/06/23/C-RPN-CVPR2019/calculate.PNG" alt="calculate" title="calculate">   </li></ol>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;C-RPN&quot;&gt;&lt;a href=&quot;#C-RPN&quot; class=&quot;headerlink&quot; title=&quot;C-RPN&quot;&gt;&lt;/a&gt;C-RPN&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;Siamese Cascaded Region Proposal Networks for Real-Time Visual Tracking&lt;/li&gt;
&lt;li&gt;Paper:&lt;/li&gt;
&lt;li&gt;Code:&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;Overview&quot;&gt;&lt;a href=&quot;#Overview&quot; class=&quot;headerlink&quot; title=&quot;Overview&quot;&gt;&lt;/a&gt;Overview&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;通过级联RPN（多stages）筛选，解决了样本不平衡问题。(多阶段筛选)&lt;/li&gt;
&lt;li&gt;构建FTB block用于高/低特征融合，结果更加精确。（多层融合）&lt;/li&gt;
&lt;li&gt;其实跟SPM Tracker的出发点相同，都是针对Siamese网络中相似物体的drift问题，解决思想也相同，都是使用多stages过滤以获得更好的效果，但是整体来说效果离SPM差很多，首先多RPN肯定很耗时，FPS在36左右，同时精度提升也不是特别明显，VOT16上EAO为0.363。&lt;/li&gt;
&lt;/ol&gt;
    
    </summary>
    
      <category term="papers" scheme="http://yoursite.com/categories/papers/"/>
    
    
      <category term="Tracking" scheme="http://yoursite.com/tags/Tracking/"/>
    
  </entry>
  
  <entry>
    <title>CIR-CVPR19-tracking</title>
    <link href="http://yoursite.com/2019/06/23/CIR-CVPR2019/"/>
    <id>http://yoursite.com/2019/06/23/CIR-CVPR2019/</id>
    <published>2019-06-23T02:20:46.000Z</published>
    <updated>2019-07-02T01:57:19.176Z</updated>
    
    <content type="html"><![CDATA[<h1 id="CIR"><a href="#CIR" class="headerlink" title="CIR"></a>CIR</h1><ul><li>Deeper and Wider Siamese Networks for Real-Time Visual Tracking</li><li>Code：<a href="https://gitlab.com/MSRA_NLPR/" target="_blank" rel="noopener">https://gitlab.com/MSRA_NLPR/</a> deeper_wider_siamese_trackers</li></ul><h2 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h2><ol><li>针对深度网络(如Resnet)无法在siamese网络取得很好的效果。SiamRPN++也是从这个点出发去做，两者的都找出了其影响最大的原因–padding，不过解决方式不同。</li><li>paper效果<ul><li>siamFC/siamRPN在VOT16上的EAO提升了23.3%和8.8%</li></ul></li></ol><a id="more"></a><h2 id="why"><a href="#why" class="headerlink" title="why"></a>why</h2><ol><li>深度网络无法在siamese网络中取得很好的效果，对网络的各部分进行了分析，大体原因如下几点：   <ul><li>神经元感受野的增大会减小特征分辨和定位的精度</li><li>网络的padding会导致网络学习的位置偏见(<strong>主要因素</strong>)</li><li>网络stride</li></ul></li></ol><h2 id="what"><a href="#what" class="headerlink" title="what"></a>what</h2><ol><li>基于残差bottleneck block进行了改进–cropping-inside residual ，用来crop(消除)padding的影响，同时可以控制感受野大小，网络的stride</li><li>几点说法<ul><li>感受野：大的感受野能够把握target的结构信息，感受野太小不利于特征提取</li><li>Stride：影响定位精度，控制着输出feature的大小；输出feature的大小影响分辨和检测精度。</li><li>Padding：当物体移动到padding边缘，会产生一定的位置偏见</li></ul></li><li>几点分析<ul><li>网络越深，感受野就越大，理论上最后一层得感受野最大</li><li>Stride为4-8-16对应得变化为0.59-0.60-0.55(Alexnet),说明siamese更适合中等strdie<strong>(4,8)</strong>，随着网络深度的增加，stride不应该增加。</li><li>最优的感受野大概为image z的<strong>60%-80%</strong></li><li>输出的feature大小较小的话，会降低track精度，因为小的feature没有组后的空间结构信息。</li><li>siamese训练的数据中object都在image的中心，所以当test数据中的object出现在image边缘时效果不好，且会受到边缘padding的影响。</li></ul></li></ol><h2 id="how"><a href="#how" class="headerlink" title="how"></a>how</h2><ol><li>基于resnet bottleneck改进–CIR Unit<ul><li>在resnet block之后添加了crop operation，将block之后padding的<strong>最外层元素</strong>给crop掉。这样feature map岂不是会越来越小？</li></ul></li><li>下采样CIR-D<ul><li>将stride由2设为1，并在block之后也加入了crop operation操作，之后又加了max pooling用于降采样</li></ul></li><li>CIR多分枝结构 - CIR-Inception/CIR-NeXt<ul><li>CIR-Inception : 在short-connection部分加入了1x1卷积，并且通过concatenation来将两个分支的feature融合</li><li>CIR-ResNeXt : 将bottleneck分为了32个分支，最终通过addition融合</li><li>这两种结构后也接crop操作，去除padding影响。这两种复杂结构可以学习更加复杂的feature</li></ul></li><li>最终，提到了crop之后feature map变小的解决方案–增大input image的大小，减小网络stride，surprise！？感觉应该有其他的方式来做padding比如说feature的均值填充之类的，没有试过不知道会不会有效果。</li></ol><h2 id="result"><a href="#result" class="headerlink" title="result"></a>result</h2><ol><li>最好结果相对SiamRPN而言，提升了4个百分点，为0.301，如图。<br><a href="&quot;result&quot;">result</a></li></ol><h2 id="other-points"><a href="#other-points" class="headerlink" title="other points"></a>other points</h2><ol><li>siamese网络的输入就是图像对，之前DaSiam就是在图像对这里使用的数据增强</li><li>如果我将z的信息提取hog或者就是feature特征，然后作为网络的input，在之后帧中判断其与之前的cosine distance,这种方案感觉也可行</li></ol>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;CIR&quot;&gt;&lt;a href=&quot;#CIR&quot; class=&quot;headerlink&quot; title=&quot;CIR&quot;&gt;&lt;/a&gt;CIR&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;Deeper and Wider Siamese Networks for Real-Time Visual Tracking&lt;/li&gt;
&lt;li&gt;Code：&lt;a href=&quot;https://gitlab.com/MSRA_NLPR/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://gitlab.com/MSRA_NLPR/&lt;/a&gt; deeper_wider_siamese_trackers&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;Overview&quot;&gt;&lt;a href=&quot;#Overview&quot; class=&quot;headerlink&quot; title=&quot;Overview&quot;&gt;&lt;/a&gt;Overview&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;针对深度网络(如Resnet)无法在siamese网络取得很好的效果。SiamRPN++也是从这个点出发去做，两者的都找出了其影响最大的原因–padding，不过解决方式不同。&lt;/li&gt;
&lt;li&gt;paper效果&lt;ul&gt;
&lt;li&gt;siamFC/siamRPN在VOT16上的EAO提升了23.3%和8.8%&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
    
    </summary>
    
      <category term="papers" scheme="http://yoursite.com/categories/papers/"/>
    
    
      <category term="Tracking" scheme="http://yoursite.com/tags/Tracking/"/>
    
  </entry>
  
  <entry>
    <title>ATOM-CVPR19-tracking</title>
    <link href="http://yoursite.com/2019/06/20/ATOM-CVPR2019/"/>
    <id>http://yoursite.com/2019/06/20/ATOM-CVPR2019/</id>
    <published>2019-06-20T02:36:44.000Z</published>
    <updated>2019-07-01T14:45:34.924Z</updated>
    
    <content type="html"><![CDATA[<h1 id="ATOM"><a href="#ATOM" class="headerlink" title="ATOM"></a>ATOM</h1><ul><li>Accurate Tracking by Overlap Maximization</li><li>Paper : </li><li>Code : <a href="https://github.com/visionml/pytracking" target="_blank" rel="noopener">https://github.com/visionml/pytracking</a></li></ul><h2 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h2><ol><li>大佬决定在跟踪精度上做改进，抛弃anchor，使用GT添加高斯噪声的方式。</li><li>受到IOUNet的启发，将class-special的IOU-Net改为target-special的IOU-Net使其适用于tracking的情境。</li><li>SGD算法收敛太慢，所以提出了新的收敛算法（共轭梯度+牛顿高斯）。</li></ol><a id="more"></a><h2 id="why"><a href="#why" class="headerlink" title="why"></a>why</h2><ol><li>近年来，大家的目光都聚焦在tracking的鲁棒性上，而忽略了tracking的准确性。</li><li>在IOUNet的启发下作的一些改进。</li></ol><h2 id="what"><a href="#what" class="headerlink" title="what"></a>what</h2><h3 id="网络结构"><a href="#网络结构" class="headerlink" title="网络结构"></a>网络结构</h3><ol><li>target分类（online）<ul><li>区分前/背景提供一个粗略的定位，online提高分类的鲁棒性</li><li>使用2层全连接层</li><li>抛弃SGD，使用共轭梯度+牛顿高斯方法优化</li></ul></li><li>target估计（offline）<ul><li>用于寻找overlap最大化的bbox，offline学习一个更通用的IoU预测表示</li><li>使用IOU-predictor网络来进行target估计</li><li>input是image object的feature和bbox_delta，然后使用PrROI pooling得到一个预定义大小的feature。</li></ul></li></ol><h2 id="how"><a href="#how" class="headerlink" title="how"></a>how</h2><ol><li>网络结构<br><img src="/2019/06/20/ATOM-CVPR2019/Network.PNG" alt="network" title="network"><ul><li>backbone ：Resnet-18（在ImageNet上预训练）</li></ul></li><li>IOU Modulation<br><img src="/2019/06/20/ATOM-CVPR2019/iou-modulation.PNG" alt="iou-modulation" title="iou-modulation"><ul><li>对reference帧和search帧进行了特征提取，之后通过channel-wise multiplication做特征融合。</li></ul></li><li>IOU predictor<ul><li>由3层FC层组成</li><li>IOU predictor input : 当前帧的feature，当前帧的bbox估计，reference帧的feature，reference帧中的target bbox</li><li>IOU predictor output : 当前帧中预测的每一个bbox的iou值</li></ul></li><li>Classifier<ul><li>2个全卷积网络</li><li>第一层由1x1卷积构成，将通道减小至64，减少计算量。</li><li>第二层使用4x4的单输出通道kernel</li><li>使用PELU作为输出的激活函数，可以忽略掉简单的负样本</li><li>第一帧，使用了数据增强(旋转，模糊，dropout等)</li><li>在分类过程中使用了自定义的优化策略（共轭梯度+牛顿高斯）<br><img src="/2019/06/20/ATOM-CVPR2019/algothm1.PNG" alt="algorithm1" title="algorithm1"></li></ul></li><li>实现细节<ul><li>使用了LaSOT和TrackingNet数据集，同时使用了COCO数据集来进行数据增强操作</li><li>图像对采样间隔为50</li><li>每个图像对，对应生成16个候选的bbox（GT+高斯噪声，同时确保最小iou为0.1）</li><li>权重初始化 -  Delving deep into rectiﬁers: Surpassing human-level performance on imagenet classiﬁcation. In ICCV, 2015. 5</li><li>loss使用MSE loss，训练40个epoch，每个epoch使用64个图像对</li><li>学习率初始为10e-3，weight decay factor为0.2（15epoch）</li><li>在训练过程中，backbone的weight被freezed</li><li>硬负样本挖掘，当distractor在分类score中取到峰值，会将该样本使用2倍的lr在优化训练一轮。同时，在score低于0.25时判断为丢失。</li><li>最后的输出使用IOU最高的3个bbox的平均值。</li></ul></li></ol><h2 id="results"><a href="#results" class="headerlink" title="results"></a>results</h2><ol><li>Nvidia GT-1080 GPU上运行30FPS<br><img src="/2019/06/20/ATOM-CVPR2019/result.PNG" alt="result" title="result"></li></ol><h2 id="other-points"><a href="#other-points" class="headerlink" title="other points"></a>other points</h2><ul><li>低层包含更多的表面信息，那为什么不用底层feature做reg,用高层语义信息去做分类。</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;ATOM&quot;&gt;&lt;a href=&quot;#ATOM&quot; class=&quot;headerlink&quot; title=&quot;ATOM&quot;&gt;&lt;/a&gt;ATOM&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;Accurate Tracking by Overlap Maximization&lt;/li&gt;
&lt;li&gt;Paper : &lt;/li&gt;
&lt;li&gt;Code : &lt;a href=&quot;https://github.com/visionml/pytracking&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://github.com/visionml/pytracking&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;Overview&quot;&gt;&lt;a href=&quot;#Overview&quot; class=&quot;headerlink&quot; title=&quot;Overview&quot;&gt;&lt;/a&gt;Overview&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;大佬决定在跟踪精度上做改进，抛弃anchor，使用GT添加高斯噪声的方式。&lt;/li&gt;
&lt;li&gt;受到IOUNet的启发，将class-special的IOU-Net改为target-special的IOU-Net使其适用于tracking的情境。&lt;/li&gt;
&lt;li&gt;SGD算法收敛太慢，所以提出了新的收敛算法（共轭梯度+牛顿高斯）。&lt;/li&gt;
&lt;/ol&gt;
    
    </summary>
    
      <category term="papers" scheme="http://yoursite.com/categories/papers/"/>
    
    
      <category term="Tracking" scheme="http://yoursite.com/tags/Tracking/"/>
    
  </entry>
  
  <entry>
    <title>IOU-Net-ECCV18-detection</title>
    <link href="http://yoursite.com/2019/06/18/IOU-Net-ECCV2018/"/>
    <id>http://yoursite.com/2019/06/18/IOU-Net-ECCV2018/</id>
    <published>2019-06-18T06:36:44.000Z</published>
    <updated>2019-07-01T14:47:29.403Z</updated>
    
    <content type="html"><![CDATA[<h1 id="IOU-Net"><a href="#IOU-Net" class="headerlink" title="IOU-Net"></a>IOU-Net</h1><ul><li>Acquisition of Localization Confidence for Accurate Object Detection</li><li>Paper : </li><li>Code : </li></ul><h2 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h2><ol><li>目前大多数的tracker都是通过cls score来确定物体的位置，但是分类得分高并不意味着定位的准确度高，所以用cls score去做NMS并不是特别合理，因为会把定位精准但分类得分低的卡掉。所以作者提出了使用iou score作为排序指标。</li><li>Paper提出了IOU-guided NMS，PrROI（使用积分的方式计算ROI特征）。</li><li>很有分量的文章，受益匪浅。</li></ol><a id="more"></a><h2 id="why"><a href="#why" class="headerlink" title="why"></a>why</h2><ol><li>使用预测box的cls score去做NMS并不合理,如图所示。<ul><li>根据皮尔逊相关系数，分类score和iou并不成正相关，而定位score和iou是成正相关。<br><img src="/2019/06/18/IOU-Net-ECCV2018/CLSvsIOU.png" alt="&quot;CLSvsIOU&quot;" title="CLSvsIOU"></li><li>并且，分类得分高的并不一定定位得分高，使用cls score做NMS会把这些定位得分高的box卡掉。<br><img src="/2019/06/18/IOU-Net-ECCV2018/CompareImg.png" alt="&quot;对比&quot;" title="对比"></li><li>通过下图也可以看出，NMS很容易把IOU较高的bbox过滤掉（当然其中肯定存在大量的冗余bbox）。<br><img src="/2019/06/18/IOU-Net-ECCV2018/IOUandBBOX.png#pic_center" alt="&quot;IOUandBBOX&quot;" title="IOUandBBOX"></li></ul></li><li>传统的基于regression的bbox refine的问题。<ul><li>regression-based和optimization-based的直观效果差距。<br><img src="/2019/06/18/IOU-Net-ECCV2018/IOUvsREG.png" alt="IOUvsREG" title="IOUvsREG"></li><li>regression-based是通过回归[cx,cy,w,h]使其与gt尽可能接近。理论上不断refine会得到很精确的结果，但是cascad RCNN相关实验表示在随着refine次数的增加效果会下降，(<strong>为什么会这样还需要做点工作</strong>)。但是使用IOU的方式在不断refine后不会出现该情况。<br><img src="/2019/06/18/IOU-Net-ECCV2018/APvsIteration.png" alt="APvsIteration" title="APvsIteration"></li></ul></li></ol><h2 id="what"><a href="#what" class="headerlink" title="what"></a>what</h2><ol><li>提出了IOU-Net来预测bbox和gt的IOU值。</li><li>将ROI pooling/Align更换为prROI。</li></ol><h2 id="how"><a href="#how" class="headerlink" title="how"></a>how</h2><h3 id="IOU-Net-1"><a href="#IOU-Net-1" class="headerlink" title="IOU-Net"></a>IOU-Net</h3><p><img src="/2019/06/18/IOU-Net-ECCV2018/Network.png#pic_center" alt="Network" title="Network"></p><ol><li>IOU predictor的input是image通过FPN后的feature。output是每个bbox的iou score。<strong>这里使用的proposal并不是来自RPN，而是通过对GT进行随机变换（添加随机噪声等）得到的一系列proposals</strong>，然后对bbox进行过滤。对于每一个bbox会使用prROI-pooling在FPN上提取的feature，这些feature被送入2层fc层做IOU预测。</li></ol><h3 id="IOU-guided-NMS"><a href="#IOU-guided-NMS" class="headerlink" title="IOU-guided NMS"></a>IOU-guided NMS</h3><p><img src="/2019/06/18/IOU-Net-ECCV2018/IOU-guided-NMS.png" alt="IOU-guided-NMS" title="IOU-guided-NMS"></p><ol><li>将NMS算法中的排序指标改为IOU score。</li><li>通过对iou进行聚类的方式对cls score进行更新(<strong>重点在第5,8行</strong>)。在根据iou过滤的过程中，将过滤掉的bboxes中的最高的cls score分配给当前的bbox，所以保留下的是其iou簇中最高的分类得分。感觉这样做的好处是消除iou一致情况下cls score的差别。</li></ol><h3 id="Optimization-based-bbox-refinement。"><a href="#Optimization-based-bbox-refinement。" class="headerlink" title="Optimization-based bbox refinement。"></a>Optimization-based bbox refinement。</h3><h4 id="IOU支路的梯度计算和参数更新"><a href="#IOU支路的梯度计算和参数更新" class="headerlink" title="IOU支路的梯度计算和参数更新"></a>IOU支路的梯度计算和参数更新</h4><p><img src="/2019/06/18/IOU-Net-ECCV2018/bbox-refinement.png" alt="bbox-refinement" title="optimization-based bbox-refinement"></p><h4 id="prROI-pooling"><a href="#prROI-pooling" class="headerlink" title="prROI pooling"></a>prROI pooling</h4><p><img src="/2019/06/18/IOU-Net-ECCV2018/ROI-pooling-align-prroi.png" alt="ROI-pooling-align-prroi" title="ROI-pooling-align-prroi"></p><ol><li>上图是ROI pooling，ROI align，prROI pooling的对比，这是三种都是基于ROI坐标根据feature map提取feature的方法。</li><li>ROI pooling。<ul><li>先将预测得到的ROI除以stride，并量化取整得到整数值的ROI</li><li>将ROI分为k*K个grid，每个grid的坐标为(x1,y1,x2,y2)，其坐标值不一定为整数，所以要量化取整，左上角向下取整，右下角向上取整，得到整数的坐标值。然后可以采用均值/最大值操作得到该grid的特征值。</li><li>优点：解决了不同大小ROI的尺寸不统一的问题</li><li>缺点：量化操作会引入一定的误差</li></ul></li><li>ROI Align<ul><li>对ROI pooling进行改进，直接使用浮点坐标值将ROI划分，消除了量化操作引入的误差。</li><li>对ROI的每个grid的坐标也不再进行量化，而是在grid中均匀取4个点，通过公式2（插值）计算得到该点的特征值（该公式根据距离对周围的4个点进行加权计算，距离越近权重越大），然后对其求平均<br><img src="/2019/06/18/IOU-Net-ECCV2018/equal-2.png" alt="equal-2" title="equal-2"></li><li>优点：消除了量化操作带来的误差</li><li>缺点：没有考虑grid的大小差异 </li></ul></li><li>PrROI pooling<ul><li>使用积分的方式计算每个grid的特征值</li><li>ROI Align仅考虑该grid中4个插值点的均值，PrROI pooling是将grid中的值看做是连续的，通过对该grid中所有点求积分得到该grid所包围点的总和，最后除以面积。<br><img src="/2019/06/18/IOU-Net-ECCV2018/equal-3.png" alt="equal-3" title="equal-3"></li><li>优点：结果会更加精准</li></ul></li></ol><h2 id="result"><a href="#result" class="headerlink" title="result"></a>result</h2><ol><li>IOU-guided NMS<br><img src="/2019/06/18/IOU-Net-ECCV2018/result-iou-nms.png" alt="result-iou-nms" title="result-iou-nms"> <ul><li>当IOU threshold设定较高时，iou nms的效果会更加明显，因为threshold较高的时候需要bbox的坐标更加准确才会能更好的AP值。</li></ul></li><li>optimization-based bbox refinement<br><img src="/2019/06/18/IOU-Net-ECCV2018/result-refinement.png" alt="result-refinement" title="result-refinement"> <ul><li>refinement在各个模块上都有不错的提升。</li></ul></li></ol><h2 id="other-points"><a href="#other-points" class="headerlink" title="other points"></a>other points</h2><h3 id="NMS"><a href="#NMS" class="headerlink" title="NMS"></a>NMS</h3><ol><li>将所有的bbox按cls score降排序生成一个list</li><li>从top 1 bbox开始，计算该bbox与其他bbox的iou，若iou大于设定阈值则剔除。</li><li>再从top 2 bbox开始，计算该bbox与其他bbox的iou…</li><li>重复操作，直到list中所有元素都筛选完毕</li></ol><h3 id="soft-NMS"><a href="#soft-NMS" class="headerlink" title="soft NMS"></a>soft NMS</h3><ul><li>并不是真正的抑制，而是对要过滤掉的bbox乘以一个衰减系数。</li></ul><ol><li>将所有的bbox按cls score降排序生成一个list</li><li>从top 1 bbox开始，计算该bbox与其他bbox的iou，若iou大于设定阈值则<strong>将其乘以一个系数，使其缩小，之后在重新比较</strong>。</li><li>再从top 2 bbox开始，计算该bbox与其他bbox的iou…</li><li>重复操作，直到list中所有元素都筛选完毕。</li><li>对于遮挡，目标密集的情况效果很好，但是对于稀疏的场景，召回率可能会低于NMS。</li></ol><h3 id="想法"><a href="#想法" class="headerlink" title="想法"></a>想法</h3><ol><li>对GT做随机调整这种方法，感觉可以用</li></ol>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;IOU-Net&quot;&gt;&lt;a href=&quot;#IOU-Net&quot; class=&quot;headerlink&quot; title=&quot;IOU-Net&quot;&gt;&lt;/a&gt;IOU-Net&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;Acquisition of Localization Confidence for Accurate Object Detection&lt;/li&gt;
&lt;li&gt;Paper : &lt;/li&gt;
&lt;li&gt;Code : &lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;Overview&quot;&gt;&lt;a href=&quot;#Overview&quot; class=&quot;headerlink&quot; title=&quot;Overview&quot;&gt;&lt;/a&gt;Overview&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;目前大多数的tracker都是通过cls score来确定物体的位置，但是分类得分高并不意味着定位的准确度高，所以用cls score去做NMS并不是特别合理，因为会把定位精准但分类得分低的卡掉。所以作者提出了使用iou score作为排序指标。&lt;/li&gt;
&lt;li&gt;Paper提出了IOU-guided NMS，PrROI（使用积分的方式计算ROI特征）。&lt;/li&gt;
&lt;li&gt;很有分量的文章，受益匪浅。&lt;/li&gt;
&lt;/ol&gt;
    
    </summary>
    
      <category term="papers" scheme="http://yoursite.com/categories/papers/"/>
    
    
      <category term="detection" scheme="http://yoursite.com/tags/detection/"/>
    
  </entry>
  
  <entry>
    <title>Canny边缘检测</title>
    <link href="http://yoursite.com/2019/05/22/canny%E8%BE%B9%E7%BC%98%E6%A3%80%E6%B5%8B/"/>
    <id>http://yoursite.com/2019/05/22/canny边缘检测/</id>
    <published>2019-05-22T02:31:46.000Z</published>
    <updated>2019-07-01T15:05:45.830Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Canny边缘检测"><a href="#Canny边缘检测" class="headerlink" title="Canny边缘检测"></a>Canny边缘检测</h1><h2 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h2><ol><li>对灰度图像统计阶跃梯度，将跃变位置连接构成图像边缘。</li><li>由于大多数传感器具有低频滤波特性，这样阶跃边缘就会变为斜坡性边缘，强度变化不是瞬间的，所以边缘检测中的第一步是滤波。</li></ol><a id="more"></a><h2 id="步骤"><a href="#步骤" class="headerlink" title="步骤"></a>步骤</h2><h3 id="滤波"><a href="#滤波" class="headerlink" title="滤波"></a>滤波</h3><ol><li>边缘检测的算法主要是基于图像强度的一阶和二阶导数，但导数通常对噪声很敏感，因此必须采用滤波器来改善与噪声有关的边缘检测器的性能。</li><li>常见的滤波算法有：高斯滤波（采用离散化的高斯函数产生一组归一化的高斯核），然后基于高斯核函数对图像灰度矩阵的每一点进行加权求和。<br>高斯核函数：$k(x, x’) = e^{-\frac{||x - x’||^2}{2\sigma^2}}$<br>sigma决定了高斯函数的宽度。高斯函数的性质：①旋转对称性；②每一个邻域像素值权值是随着该点到中心点的距离单调递减的。</li></ol><h3 id="增强"><a href="#增强" class="headerlink" title="增强"></a>增强</h3><ol><li>确定图像各点邻域强度的变化值，增强算法可以将图像灰度点邻域强度值有显著变化的点凸显出来。</li><li>编程中，可以通过梯度幅值来确定。</li></ol><h3 id="检测"><a href="#检测" class="headerlink" title="检测"></a>检测</h3><ol><li>经过增强的图像，往往邻域中有很多点的梯度值比较大，而在特定的应用中，这些点并不是我们要找的边缘点，所以应该采用某种方法来对这些点进行取舍。</li><li>实际工程中，常用的方法是通过阈值化方法来检测。</li></ol><h2 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h2><h3 id="对原始图像灰度化"><a href="#对原始图像灰度化" class="headerlink" title="对原始图像灰度化"></a>对原始图像灰度化</h3><ol><li>灰度化就是对图像各个通道的采样值进行加权平均。</li><li>Gray = (R+G+B)/3 或者 Gray = 0.299R+0.587G+0.114B</li></ol><h3 id="对图像进行高斯滤波"><a href="#对图像进行高斯滤波" class="headerlink" title="对图像进行高斯滤波"></a>对图像进行高斯滤波</h3><ol><li>两个一维高斯核进行两次加权实现，或者一个二维高斯核进行一次卷积实现。</li><li>$k(x, x’) = 1/{sqrt(2<em>pi)</em>sigma^2}*e^{-\frac{x^2+y^2}{2\sigma^2}}$</li><li>图像的高斯滤波，根据待滤波的像素点及其邻域点的灰度值按照一定的参数规则进行加权平均。这样可以有效滤去理想图像中叠加的高频噪声。</li></ol><h3 id="用一阶偏导的有限差分来计算梯度的幅值和方向"><a href="#用一阶偏导的有限差分来计算梯度的幅值和方向" class="headerlink" title="用一阶偏导的有限差分来计算梯度的幅值和方向"></a>用一阶偏导的有限差分来计算梯度的幅值和方向</h3><ol><li>Roberts算子，Sobel算子，Prewitt算子</li><li>canny用到的算子是sx = [-1,1,-1,1],sy = [1,-1,1,-1]</li></ol><h3 id="对梯度幅值进行非极大值抑制"><a href="#对梯度幅值进行非极大值抑制" class="headerlink" title="对梯度幅值进行非极大值抑制"></a>对梯度幅值进行非极大值抑制</h3><ol><li>图像梯度幅值矩阵的元素值越大，说明该点的梯度值越大，但不能说明该店就是边缘。</li><li>寻找像素点局部最大值，将非极大值所对应的灰度值置为0。</li><li>非最大抑制是回答这样一个问题：“当前的梯度值在梯度方向上是一个局部最大值吗？” 所以,要把当前位置的梯度值与梯度方向上两侧的梯度值进行比较；</li><li>梯度方向垂直于边缘方向。只能得到C点邻域的8个点的值，而dTmp1和dTmp2并不在其中，要得到这两个值就需要对该两个点两端的已知灰度进行线性插值，也即根据图1中的g1和g2对dTmp1进行插值。</li><li>完成非极大值抑制后，会得到一个二值图像，非边缘的点灰度值均为0，可能为边缘的局部灰度极大值点可设置其灰度为128。</li><li>这样一个检测结果还是包含了很多由噪声及其他原因造成的假边缘。因此还需要进一步的处理。</li></ol><h3 id="用双阈值算法检测和连接边缘"><a href="#用双阈值算法检测和连接边缘" class="headerlink" title="用双阈值算法检测和连接边缘"></a>用双阈值算法检测和连接边缘</h3><ol><li>在高阈值图像中把边缘链接成轮廓，当到达轮廓的端点时，该算法会在断点的8邻域点中寻找满足低阈值的点，再根据此点收集新的边缘，直到整个图像边缘闭合。</li></ol>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;Canny边缘检测&quot;&gt;&lt;a href=&quot;#Canny边缘检测&quot; class=&quot;headerlink&quot; title=&quot;Canny边缘检测&quot;&gt;&lt;/a&gt;Canny边缘检测&lt;/h1&gt;&lt;h2 id=&quot;Overview&quot;&gt;&lt;a href=&quot;#Overview&quot; class=&quot;headerlink&quot; title=&quot;Overview&quot;&gt;&lt;/a&gt;Overview&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;对灰度图像统计阶跃梯度，将跃变位置连接构成图像边缘。&lt;/li&gt;
&lt;li&gt;由于大多数传感器具有低频滤波特性，这样阶跃边缘就会变为斜坡性边缘，强度变化不是瞬间的，所以边缘检测中的第一步是滤波。&lt;/li&gt;
&lt;/ol&gt;
    
    </summary>
    
      <category term="image-processing" scheme="http://yoursite.com/categories/image-processing/"/>
    
    
      <category term="Canny" scheme="http://yoursite.com/tags/Canny/"/>
    
  </entry>
  
  <entry>
    <title>Tracking-Summary</title>
    <link href="http://yoursite.com/2019/05/19/Tracking-Summary/"/>
    <id>http://yoursite.com/2019/05/19/Tracking-Summary/</id>
    <published>2019-05-19T13:56:21.000Z</published>
    <updated>2019-07-01T15:03:13.705Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Tracking-Summary"><a href="#Tracking-Summary" class="headerlink" title="Tracking-Summary"></a>Tracking-Summary</h1><ul><li>总结一下近年来比较经典的tracker,未完待续</li></ul><a id="more"></a><h2 id="综述"><a href="#综述" class="headerlink" title="综述"></a>综述</h2><h3 id="难点"><a href="#难点" class="headerlink" title="难点"></a>难点</h3><ul><li>外观的形变，光照变换，快速运动，运动模糊，背景相似干扰，遮挡，旋转，尺度变换，出视野<h3 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h3></li><li>OTB<br>OTB包含0.25的灰度序列</li><li>VOT<br>vot是彩色序列，且分辨率较高，精细标注，评价指标更好</li><li>差别   <ul><li>OTB有随机帧开始，或者矩形框随机干扰初始化去跑</li><li>VOT是用第一帧初始化，每次跟踪失败，５帧之后重新初始化<h3 id="类别"><a href="#类别" class="headerlink" title="类别"></a>类别</h3><h4 id="生成式模型"><a href="#生成式模型" class="headerlink" title="生成式模型"></a>生成式模型</h4></li></ul></li><li>对第一帧的目标区域建模，下一帧寻找与模型最相似的区域作为预测区域。</li><li><strong>方法</strong>：卡尔曼滤波，粒子滤波，mean-shift</li><li><strong>代表</strong>：ASMS,DAT（ASMS仅使用颜色特征，切且速度较快，125fps，在mean-shift框架下加入了尺度估计，加入了尺度不剧变，可能偏最大的两个先验的正则项，再加反向尺度一致性检查）。<h4 id="判别式模型"><a href="#判别式模型" class="headerlink" title="判别式模型"></a>判别式模型</h4></li><li>将当前帧的目标区域作为正样本，背景区域作为负样本来训练分类器。（相比较生成式模型使用了背景信息，效果会更好一些）</li><li><strong>方法</strong>：<br>传统的机器学习算法，相关滤波，深度学习</li><li><strong>代表</strong>：<br>传统－－Struck，TLD(struck使用了haar+structured output SVM，跟踪中进行多尺度便利搜索来完成尺度自适应)<br>相关滤波－－KCF,CSK,DAT<br>深度学习－－MDNet,TCNN,SiamFC</li></ul><h3 id="传统机器学习方法"><a href="#传统机器学习方法" class="headerlink" title="传统机器学习方法"></a>传统机器学习方法</h3><h4 id="Struck-2012-20fps"><a href="#Struck-2012-20fps" class="headerlink" title="Struck - 2012 - 20fps"></a>Struck - 2012 - 20fps</h4><h3 id="相关滤波－CF"><a href="#相关滤波－CF" class="headerlink" title="相关滤波－CF"></a>相关滤波－CF</h3><p><strong>推荐</strong>：<a href="https://github.com/HEscop/TBCF" title="大佬维护的CF资源" target="_blank" rel="noopener">大佬维护的CF资源</a></p><h4 id="MOSSE-615fps"><a href="#MOSSE-615fps" class="headerlink" title="MOSSE -      - 615fps"></a>MOSSE -      - 615fps</h4><ul><li>单通道灰度特征的相关滤波</li></ul><h4 id="CSK-362fps"><a href="#CSK-362fps" class="headerlink" title="CSK -      - 362fps"></a>CSK -      - 362fps</h4><ul><li>岭回归，循环移位的近似密集采样，多通道HOG特征</li><li>CSK在MOSSE的基础上扩展了密集采样和kernel-trick</li></ul><h4 id="KCF-2014-172fps-hog"><a href="#KCF-2014-172fps-hog" class="headerlink" title="KCF - 2014 - 172fps(hog)"></a>KCF - 2014 - 172fps(hog)</h4><ul><li>在CSK基础上扩展了多通道梯度的HOG特征(梯度特征)</li></ul><h4 id="DCF-2014-292fps-hog"><a href="#DCF-2014-292fps-hog" class="headerlink" title="DCF - 2014 - 292fps(hog)"></a>DCF - 2014 - 292fps(hog)</h4><h4 id="CN-2014-152fps"><a href="#CN-2014-152fps" class="headerlink" title="CN - 2014 - 152fps"></a>CN - 2014 - 152fps</h4><ul><li>在CSK基础上扩展了多通道CN特征(颜色特征)<h4 id="相关知识点"><a href="#相关知识点" class="headerlink" title="相关知识点"></a>相关知识点</h4></li></ul><ol><li><a href="https://blog.csdn.net/zouxy09/article/details/7929348" title="参考" target="_blank" rel="noopener">HOG特征</a>   </li></ol><ul><li>主要思想：梯度的统计信息，梯度主要存在于边缘的地方。</li><li>实现过程   <ul><li>灰度化（将图像看做一个x,y,z（灰度）的三维图像）；</li><li>采用Gamma校正法对输入图像进行颜色空间的标准化（归一化）；目的是调节图像的对比度，降低图像局部的阴影和光照变化所造成的影响，同时可以抑制噪音的干扰；</li><li>计算图像每个像素的梯度（包括大小和方向）；主要是为了捕获轮廓信息，同时进一步弱化光照的干扰。计算图像梯度。计算图像横/纵坐标方向的梯度(就是该像素在横纵方向上的相邻像素去做差,常用的方法是用[-1,0,1]梯度算子对原图像做卷积运算得到ｘ方向的梯度分量，同理，使用[-1,0,1]运算得到y方向上的梯度分量)，并计算每个像素位置的梯度方向值。</li><li>将图像划分成小cells（例如6*6像素/cell）；</li><li>统计每个cell的梯度直方图（不同梯度的个数），即可形成每个cell的descriptor；</li><li>将每几个cell组成一个block（例如3*3个cell/block），一个block内所有cell的特征descriptor串联起来便得到该block的HOG特征descriptor。</li><li>将图像image内的所有block的HOG特征descriptor串联起来就可以得到该image（你要检测的目标）的HOG特征descriptor了。这个就是最终的可供分类使用的特征向量了。</li></ul></li></ul><h3 id="深度学习-DL"><a href="#深度学习-DL" class="headerlink" title="深度学习-DL"></a>深度学习-DL</h3>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;Tracking-Summary&quot;&gt;&lt;a href=&quot;#Tracking-Summary&quot; class=&quot;headerlink&quot; title=&quot;Tracking-Summary&quot;&gt;&lt;/a&gt;Tracking-Summary&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;总结一下近年来比较经典的tracker,未完待续&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
      <category term="summary" scheme="http://yoursite.com/categories/summary/"/>
    
    
      <category term="Tracking" scheme="http://yoursite.com/tags/Tracking/"/>
    
  </entry>
  
  <entry>
    <title>GIOU-CVPR19-detection</title>
    <link href="http://yoursite.com/2019/05/09/GIOU-CVPR19-detection/"/>
    <id>http://yoursite.com/2019/05/09/GIOU-CVPR19-detection/</id>
    <published>2019-05-09T13:56:21.000Z</published>
    <updated>2019-05-10T16:15:30.486Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h1><h2 id="主要思想"><a href="#主要思想" class="headerlink" title="主要思想"></a>主要思想</h2><ul><li>提出新的loss指标GIOU,使用评价标准作为loss，同时避免了IOU作为loss的缺点，有较好的提升。    <h2 id="效果"><a href="#效果" class="headerlink" title="效果"></a>效果</h2></li><li>在anchor较少的detection中有较为明显的提升(3-6个点)   <h2 id="paper"><a href="#paper" class="headerlink" title="paper"></a>paper</h2><ul><li><a href="https://arxiv.org/pdf/1902.09630.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1902.09630.pdf</a></li></ul></li></ul><a id="more"></a><h1 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h1><ol><li>大家都在模型，trick上下功夫，忽略了在L1/L2上的改进(L_n范数对物体的scale比较敏感)。</li><li>直接使用iou作为loss存在的问题。<ul><li>两个框没有相交，IOU=0，loss = 0,无法进行梯度的反向传播，无法学习训练。</li><li>IOU无法精确衡量重叠程度，且IOU的变化无法反馈定位框的重合度和方向。如下图。   <img src="/2019/05/09/GIOU-CVPR19-detection/IOU_vs_GIOU.PNG" alt="IOU vs GIOU" title="IOU vs GIOU"></li></ul></li></ol><h1 id="Method"><a href="#Method" class="headerlink" title="Method"></a>Method</h1><ol><li>设定gt为A，pred为B，先求包含A，B的最小闭包C。</li><li>计算C中去除A∪B后剩下的面积D，即D = C\(A∪B)。</li><li>计算IoU</li><li>GIoU = IoU - D/C   </li><li>IOU ∈ [0,1]，GIOU ∈ [-1,1]<br><img src="/2019/05/09/GIOU-CVPR19-detection/InkedGIoU_LI.jpg" alt="GIoU" title="GIoU"></li></ol><h1 id="Others"><a href="#Others" class="headerlink" title="Others"></a>Others</h1><h2 id="obtains"><a href="#obtains" class="headerlink" title="obtains"></a>obtains</h2><ul><li>起初自己也想过使用iou作为loss，但是看到网上说iou作为loss可能存在梯度无法回传问题时，没有多思考去寻找解决办法。所以，遇到问题深究原因，考虑有没有可替代的近似方案。</li><li>IOU既然对于尺度不敏感，L_n对尺度敏感，那两者就可以做loss的结合。</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;Overview&quot;&gt;&lt;a href=&quot;#Overview&quot; class=&quot;headerlink&quot; title=&quot;Overview&quot;&gt;&lt;/a&gt;Overview&lt;/h1&gt;&lt;h2 id=&quot;主要思想&quot;&gt;&lt;a href=&quot;#主要思想&quot; class=&quot;headerlink&quot; title=&quot;主要思想&quot;&gt;&lt;/a&gt;主要思想&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;提出新的loss指标GIOU,使用评价标准作为loss，同时避免了IOU作为loss的缺点，有较好的提升。    &lt;h2 id=&quot;效果&quot;&gt;&lt;a href=&quot;#效果&quot; class=&quot;headerlink&quot; title=&quot;效果&quot;&gt;&lt;/a&gt;效果&lt;/h2&gt;&lt;/li&gt;
&lt;li&gt;在anchor较少的detection中有较为明显的提升(3-6个点)   &lt;h2 id=&quot;paper&quot;&gt;&lt;a href=&quot;#paper&quot; class=&quot;headerlink&quot; title=&quot;paper&quot;&gt;&lt;/a&gt;paper&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1902.09630.pdf&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://arxiv.org/pdf/1902.09630.pdf&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
      <category term="papers" scheme="http://yoursite.com/categories/papers/"/>
    
    
      <category term="detection" scheme="http://yoursite.com/tags/detection/"/>
    
  </entry>
  
</feed>
